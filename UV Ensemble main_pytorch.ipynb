{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, recall_score\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading CSV data\n",
      "Exams data: 1631 rows\n",
      "Labels data: 815 rows\n"
     ]
    }
   ],
   "source": [
    "# Loading CSV data\n",
    "print(\"Step 1: Loading CSV data\")\n",
    "exams_df = pd.read_csv('exams.csv')\n",
    "labels_df = pd.read_csv('samitrop_chagas_labels.csv')\n",
    "\n",
    "print(f\"Exams data: {len(exams_df)} rows\")\n",
    "print(f\"Labels data: {len(labels_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exams data sample:\n",
      "   exam_id  age  is_male  normal_ecg  death     timey  nn_predicted_age\n",
      "0   294669   67     True       False  False  2.116020         51.093110\n",
      "1   291318   65     True       False  False  3.077345         76.923935\n",
      "2   247007   67    False       False  False  2.378450         61.212074\n",
      "\n",
      "Labels data sample:\n",
      "   exam_id  chagas\n",
      "0   247007    True\n",
      "1   181629    True\n",
      "2   406936    True\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "print(\"\\nExams data sample:\")\n",
    "print(exams_df.head(3))\n",
    "print(\"\\nLabels data sample:\")\n",
    "print(labels_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total records: 1631\n"
     ]
    }
   ],
   "source": [
    "# Set all exams as negative by default\n",
    "exams_df['chagas'] = 0\n",
    "\n",
    "# Update the chagas labels for the 815 IDs in labels_df to be positive\n",
    "exams_df.loc[exams_df['exam_id'].isin(labels_df['exam_id']), 'chagas'] = 1\n",
    "\n",
    "\n",
    "merged_df = exams_df\n",
    "print(f\"\\nTotal records: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chagas positive: 815 (49.97%)\n",
      "Chagas negative: 816 (50.03%)\n"
     ]
    }
   ],
   "source": [
    "# Check class balance\n",
    "chagas_count = merged_df['chagas'].sum()\n",
    "print(f\"Chagas positive: {chagas_count} ({chagas_count/len(merged_df)*100:.2f}%)\")\n",
    "print(f\"Chagas negative: {len(merged_df) - chagas_count} ({(1-chagas_count/len(merged_df))*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Loading ECG data from HDF5 file\n",
      "HDF5 file structure:\n",
      "Key: tracings\n",
      "  Type: Dataset\n",
      "  Shape: (1631, 4096, 12)\n",
      "\n",
      "Accessing 'tracings' dataset\n",
      "Tracings shape: (1631, 4096, 12)\n",
      "No explicit exam_id mapping found. Assuming sequential ordering.\n",
      "\n",
      "Loading ECG data...\n",
      "  Progress: 0/1631 ECGs loaded\n",
      "  First ECG shape: (4096, 12)\n",
      "  Progress: 100/1631 ECGs loaded\n",
      "  Progress: 200/1631 ECGs loaded\n",
      "  Progress: 300/1631 ECGs loaded\n",
      "  Progress: 400/1631 ECGs loaded\n",
      "  Progress: 500/1631 ECGs loaded\n",
      "  Progress: 600/1631 ECGs loaded\n",
      "  Progress: 700/1631 ECGs loaded\n",
      "  Progress: 800/1631 ECGs loaded\n",
      "  Progress: 900/1631 ECGs loaded\n",
      "  Progress: 1000/1631 ECGs loaded\n",
      "  Progress: 1100/1631 ECGs loaded\n",
      "  Progress: 1200/1631 ECGs loaded\n",
      "  Progress: 1300/1631 ECGs loaded\n",
      "  Progress: 1400/1631 ECGs loaded\n",
      "  Progress: 1500/1631 ECGs loaded\n",
      "  Progress: 1600/1631 ECGs loaded\n"
     ]
    }
   ],
   "source": [
    "# Loading ECG data from HDF5 file\n",
    "print(\"\\nStep 2: Loading ECG data from HDF5 file\")\n",
    "\n",
    "if not os.path.exists('exams.hdf5'):\n",
    "    raise FileNotFoundError(\"The file 'exams.hdf5' was not found in the current directory.\")\n",
    "\n",
    "# Open HDF5 file\n",
    "with h5py.File('exams.hdf5', 'r') as hdf:\n",
    "    # Print the structure of the HDF5 file\n",
    "    print(\"HDF5 file structure:\")\n",
    "    for key in hdf.keys():\n",
    "        print(f\"Key: {key}\")\n",
    "        if isinstance(hdf[key], h5py.Group):\n",
    "            print(f\"  Type: Group\")\n",
    "            for subkey in hdf[key].keys():\n",
    "                print(f\"  Subkey: {subkey}\")\n",
    "        else:\n",
    "            print(f\"  Type: Dataset\")\n",
    "            print(f\"  Shape: {hdf[key].shape}\")\n",
    "    \n",
    "    # Since HDF5 has a 'tracings' key\n",
    "    if 'tracings' in hdf:\n",
    "        print(\"\\nAccessing 'tracings' dataset\")\n",
    "        tracings = hdf['tracings']\n",
    "        print(f\"Tracings shape: {tracings.shape}\")\n",
    "        \n",
    "        # Checking if there's an 'exam_id' dataset that maps indices to exam_ids\n",
    "        if 'exam_id' in hdf:\n",
    "            # If there's a mapping between indices and exam_ids\n",
    "            exam_id_mapping = hdf['exam_id'][:]\n",
    "            print(f\"Found exam_id mapping with {len(exam_id_mapping)} entries\")\n",
    "        else:\n",
    "            # If there's no explicit mapping, we'll need to determine how tracings map to exam_ids\n",
    "            print(\"No explicit exam_id mapping found. Assuming sequential ordering.\")\n",
    "            # Here we're assuming that the order of tracings corresponds to the order of exam_ids in the CSV\n",
    "            exam_id_mapping = merged_df['exam_id'].values\n",
    "            if len(exam_id_mapping) != tracings.shape[0]:\n",
    "                print(f\"Warning: Number of tracings ({tracings.shape[0]}) doesn't match number of exam_ids ({len(exam_id_mapping)})\")\n",
    "                # Use the minimum number to avoid index errors\n",
    "                min_length = min(len(exam_id_mapping), tracings.shape[0])\n",
    "                exam_id_mapping = exam_id_mapping[:min_length]\n",
    "                print(f\"Using first {min_length} exam_ids for mapping\")\n",
    "        \n",
    "        # Initialize lists to store ECG data and labels\n",
    "        ecg_data = []\n",
    "        labels = []\n",
    "        original_ids = []\n",
    "        \n",
    "        # Load ECG data for each exam\n",
    "        print(\"\\nLoading ECG data...\")\n",
    "        for i in range(len(exam_id_mapping)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"  Progress: {i}/{len(exam_id_mapping)} ECGs loaded\")\n",
    "            \n",
    "            # Get the exam_id for this tracing\n",
    "            exam_id = exam_id_mapping[i]\n",
    "            \n",
    "            # Get the label from our merged dataframe\n",
    "            label_row = merged_df.loc[merged_df['exam_id'] == exam_id]\n",
    "            if len(label_row) == 0:\n",
    "                print(f\"  Warning: No label found for ID {exam_id}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            label = label_row['chagas'].values[0]\n",
    "            \n",
    "            try:\n",
    "                # Get the ECG data\n",
    "                ecg = tracings[i]\n",
    "                \n",
    "                # Check and fix shape if needed\n",
    "                if len(ecg.shape) == 1:\n",
    "                    # If it's one-dimensional, reshape it\n",
    "                    print(f\"  Single-dimension ECG found with shape {ecg.shape}. Reshaping...\")\n",
    "                    # Assume it's 12 leads concatenated\n",
    "                    n_samples = ecg.shape[0] // 12\n",
    "                    ecg = ecg.reshape(n_samples, 12)\n",
    "                \n",
    "                # Print shape info for the first ECG\n",
    "                if i == 0:\n",
    "                    print(f\"  First ECG shape: {ecg.shape}\")\n",
    "                    # If shape is (12, time_points) instead of (time_points, 12), transpose it\n",
    "                    if ecg.shape[1] != 12 and ecg.shape[0] == 12:\n",
    "                        print(\"  Transposing ECG data to get (time_points, leads) format\")\n",
    "                        ecg = ecg.T\n",
    "                        print(f\"  Transposed shape: {ecg.shape}\")\n",
    "                \n",
    "                # Add to lists\n",
    "                ecg_data.append(ecg)\n",
    "                labels.append(label)\n",
    "                original_ids.append(exam_id)\n",
    "            except Exception as e:\n",
    "                print(f\"  Error loading ECG for ID {exam_id}: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        raise ValueError(\"Expected 'tracings' dataset not found in HDF5 file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1631 ECGs\n",
      "Final ECG data shape: (1631, 4096, 12)\n",
      "Labels shape: (1631,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if we loaded any data\n",
    "if len(ecg_data) == 0:\n",
    "    raise ValueError(\"No ECG data was successfully loaded. Cannot proceed.\")\n",
    "\n",
    "print(f\"Successfully loaded {len(ecg_data)} ECGs\")\n",
    "\n",
    "# Check if ECGs have consistent shapes\n",
    "shapes = [ecg.shape for ecg in ecg_data]\n",
    "unique_shapes = set(shapes)\n",
    "if len(unique_shapes) > 1:\n",
    "    print(f\"Warning: Inconsistent ECG shapes detected. Found {len(unique_shapes)} different shapes.\")\n",
    "    \n",
    "    # Finding the most common shape\n",
    "    most_common_shape = max(unique_shapes, key=shapes.count)\n",
    "    print(f\"Using most common shape: {most_common_shape}\")\n",
    "    \n",
    "    # Filter to keep only ECGs with the most common shape\n",
    "    filtered_data = []\n",
    "    filtered_labels = []\n",
    "    filtered_ids = []\n",
    "    for i in range(len(ecg_data)):\n",
    "        if ecg_data[i].shape == most_common_shape:\n",
    "            filtered_data.append(ecg_data[i])\n",
    "            filtered_labels.append(labels[i])\n",
    "            filtered_ids.append(original_ids[i])\n",
    "    \n",
    "    ecg_data = filtered_data\n",
    "    labels = filtered_labels\n",
    "    original_ids = filtered_ids\n",
    "    print(f\"After filtering: {len(ecg_data)} ECGs with consistent shape\")\n",
    "\n",
    "# Create numpy arrays for model training\n",
    "# Ensure all ECGs have the same length\n",
    "if len(ecg_data) > 0:\n",
    "    time_points = max(ecg.shape[0] for ecg in ecg_data)\n",
    "    n_leads = ecg_data[0].shape[1]  # Typically 12 for standard ECG\n",
    "    \n",
    "    X = np.zeros((len(ecg_data), time_points, n_leads))\n",
    "    for i, ecg in enumerate(ecg_data):\n",
    "        # Pad or truncate to the same length\n",
    "        if ecg.shape[0] < time_points:\n",
    "            # Pad with zeros\n",
    "            X[i, :ecg.shape[0], :] = ecg\n",
    "        else:\n",
    "            # Truncate\n",
    "            X[i, :, :] = ecg[:time_points, :]\n",
    "            \n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"Final ECG data shape: {X.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Preprocessing ECG data\n",
      "Training set size: (1304, 4096, 12)\n",
      "Testing set size: (327, 4096, 12)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess ECG data\n",
    "print(\"\\nStep 3: Preprocessing ECG data\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    X, y, X_indices, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "\n",
    "# Normalize each ECG to have zero mean and unit variance\n",
    "for i in range(X_train.shape[0]):\n",
    "    for lead in range(X_train.shape[2]):\n",
    "        # Avoid division by zero\n",
    "        std = np.std(X_train[i, :, lead])\n",
    "        if std == 0:\n",
    "            X_train[i, :, lead] = 0\n",
    "        else:\n",
    "            X_train[i, :, lead] = (X_train[i, :, lead] - np.mean(X_train[i, :, lead])) / std\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    for lead in range(X_test.shape[2]):\n",
    "        # Avoid division by zero\n",
    "        std = np.std(X_test[i, :, lead])\n",
    "        if std == 0:\n",
    "            X_test[i, :, lead] = 0\n",
    "        else:\n",
    "            X_test[i, :, lead] = (X_test[i, :, lead] - np.mean(X_test[i, :, lead])) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Visualizing sample ECGs\n",
      "Sample ECGs saved to 'sample_ecgs.png'\n"
     ]
    }
   ],
   "source": [
    "#  Visualize sample ECGs\n",
    "print(\"\\nStep 4: Visualizing sample ECGs\")\n",
    "\n",
    "# Get indices of Chagas positive and negative samples\n",
    "pos_indices = np.where(y == 1)[0]\n",
    "neg_indices = np.where(y == 0)[0]\n",
    "\n",
    "# Check if we have samples of both classes\n",
    "if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "    # Number of samples to visualize\n",
    "    n_samples = 2\n",
    "    \n",
    "    # Plot Chagas positive and negative samples\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot Chagas positive samples\n",
    "    for i in range(min(n_samples, len(pos_indices))):\n",
    "        idx = pos_indices[i]\n",
    "        plt.subplot(2, n_samples, i+1)\n",
    "        \n",
    "        # Plot all leads\n",
    "        for lead in range(X.shape[2]):\n",
    "            plt.plot(X[idx, :, lead], alpha=0.7, linewidth=0.5)\n",
    "        \n",
    "        plt.title(f\"Chagas Positive (ID: {original_ids[idx]})\")\n",
    "        plt.ylim(-5, 5)\n",
    "    \n",
    "    # Plot Chagas negative samples\n",
    "    for i in range(min(n_samples, len(neg_indices))):\n",
    "        idx = neg_indices[i]\n",
    "        plt.subplot(2, n_samples, i+n_samples+1)\n",
    "        \n",
    "        # Plot all leads\n",
    "        for lead in range(X.shape[2]):\n",
    "            plt.plot(X[idx, :, lead], alpha=0.7, linewidth=0.5)\n",
    "        \n",
    "        plt.title(f\"Chagas Negative (ID: {original_ids[idx]})\")\n",
    "        plt.ylim(-5, 5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_ecgs.png')\n",
    "    plt.close()\n",
    "    print(\"Sample ECGs saved to 'sample_ecgs.png'\")\n",
    "else:\n",
    "    print(\"Cannot visualize: missing examples from one or both classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Creating PyTorch Dataset and DataLoader\n",
      "Created train_loader with 82 batches of size 16\n",
      "Created test_loader with 21 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset and DataLoader\n",
    "print(\"\\nStep 5: Creating PyTorch Dataset and DataLoader\")\n",
    "\n",
    "# Define a custom Dataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, ecg_data, labels):\n",
    "        self.ecg_data = torch.tensor(ecg_data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ecg_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ecg = self.ecg_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return ecg, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset = ECGDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Created train_loader with {len(train_loader)} batches of size {batch_size}\")\n",
    "print(f\"Created test_loader with {len(test_loader)} batches of size {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Building PyTorch CNN model\n",
      "Using device: cpu\n",
      "ECGModel(\n",
      "  (conv1): Conv1d(12, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=131072, out_features=64, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 8433729\n"
     ]
    }
   ],
   "source": [
    "# Define PyTorch model\n",
    "print(\"\\nStep 6: Building PyTorch CNN model\")\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the CNN model\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=12):\n",
    "        super(ECGModel, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the size of flattened features after convolutions and pooling\n",
    "        # For a time series of length L, after two pooling layers of kernel_size=2, we have L/4\n",
    "        self.flattened_size = (time_points // 4) * 128\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # PyTorch Conv1d expects input shape (batch_size, channels, seq_length)\n",
    "        # Our data is (batch_size, seq_length, channels), so we need to permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu3(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = ECGModel(input_channels=n_leads)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Training model\n",
      "Epoch [1/2], Batch [10/82], Loss: 0.6707\n",
      "Epoch [1/2], Batch [20/82], Loss: 0.6227\n",
      "Epoch [1/2], Batch [30/82], Loss: 0.4750\n",
      "Epoch [1/2], Batch [40/82], Loss: 0.6860\n",
      "Epoch [1/2], Batch [50/82], Loss: 0.7660\n",
      "Epoch [1/2], Batch [60/82], Loss: 0.4976\n",
      "Epoch [1/2], Batch [70/82], Loss: 0.6168\n",
      "Epoch [1/2], Batch [80/82], Loss: 0.5092\n",
      "Epoch [1/2] - 23.13s - Loss: 0.5492, Acc: 0.7117, Val Loss: 0.7789, Val Acc: 0.5046\n",
      "Epoch [2/2], Batch [10/82], Loss: 0.4349\n",
      "Epoch [2/2], Batch [20/82], Loss: 0.5587\n",
      "Epoch [2/2], Batch [30/82], Loss: 0.4524\n",
      "Epoch [2/2], Batch [40/82], Loss: 0.4829\n",
      "Epoch [2/2], Batch [50/82], Loss: 0.5040\n",
      "Epoch [2/2], Batch [60/82], Loss: 0.4658\n",
      "Epoch [2/2], Batch [70/82], Loss: 0.4022\n",
      "Epoch [2/2], Batch [80/82], Loss: 0.5325\n",
      "Epoch [2/2] - 23.01s - Loss: 0.4285, Acc: 0.7975, Val Loss: 0.9471, Val Acc: 0.5443\n",
      "Loaded best model with validation loss: 0.7789\n",
      "Training history saved to 'training_history.png'\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "print(\"\\nStep 8: Training model\")\n",
    "\n",
    "# Tracking variables\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "num_epochs = 2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Print progress\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate validation statistics\n",
    "    val_epoch_loss = val_loss / len(test_dataset)\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accs.append(val_epoch_acc)\n",
    "    \n",
    "    # Print epoch results\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - {epoch_time:.2f}s - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Loaded best model with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(val_accs, label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()\n",
    "print(\"Training history saved to 'training_history.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluating model\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.49      0.52       164\n",
      "         1.0       0.54      0.60      0.57       163\n",
      "\n",
      "    accuracy                           0.54       327\n",
      "   macro avg       0.55      0.54      0.54       327\n",
      "weighted avg       0.55      0.54      0.54       327\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[80 84]\n",
      " [65 98]]\n",
      "ROC curve saved to 'roc_curve.png'\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(\" Evaluating model\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize arrays to store predictions and true labels\n",
    "all_preds = []\n",
    "all_preds_prob = []\n",
    "all_labels = []\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert to CPU and numpy for evaluation\n",
    "        preds_prob = outputs.cpu().numpy()\n",
    "        preds = (outputs > 0.5).float().cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        # Append batch predictions to lists\n",
    "        all_preds.extend(preds)\n",
    "        all_preds_prob.extend(preds_prob)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_preds_prob = np.array(all_preds_prob).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_preds_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.close()\n",
    "print(\"ROC curve saved to 'roc_curve.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10: Saving results\n",
      "Model saved to 'chagas_detection_model.pth'\n",
      "Predictions saved to 'chagas_predictions.csv'\n",
      "\n",
      "Script completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model and results\n",
    "print(\"\\nStep 10: Saving results\")\n",
    "\n",
    "# Save PyTorch model\n",
    "torch.save(model.state_dict(), 'chagas_detection_model.pth')\n",
    "print(\"Model saved to 'chagas_detection_model.pth'\")\n",
    "\n",
    "# Map back to original exam IDs\n",
    "original_test_ids = [original_ids[i] for i in test_indices]\n",
    "\n",
    "# Create DataFrame with predictions for future use\n",
    "predictions_df = pd.DataFrame({\n",
    "    'exam_id': original_test_ids,\n",
    "    'true_chagas': all_labels,\n",
    "    'predicted_prob': all_preds_prob,\n",
    "    'predicted_chagas': all_preds\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('chagas_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'chagas_predictions.csv'\")\n",
    "\n",
    "print(\"\\nScript completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Row-wise CNN model (analyzes each lead over time)\n",
    "class RowWiseECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=12):\n",
    "        super(RowWiseECGModel, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the size of flattened features after convolutions and pooling\n",
    "        # For a time series of length L, after two pooling layers of kernel_size=2, we have L/4\n",
    "        self.flattened_size = (time_points // 4) * 128\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # PyTorch Conv1d expects input shape (batch_size, channels, seq_length)\n",
    "        # Our data is (batch_size, seq_length, channels), so we need to permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu3(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Column-wise CNN model (analyzes across leads at each time point)\n",
    "class ColumnWiseECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=time_points):\n",
    "        super(ColumnWiseECGModel, self).__init__()\n",
    "        \n",
    "        # First convolutional block - now operating across leads at each time point\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the size of flattened features after convolutions and pooling\n",
    "        # For leads dimension, which is typically 12, after pooling it becomes 12/4 = 3 (or less if leads < 12)\n",
    "        self.flattened_size = (n_leads // 4 if n_leads >= 4 else 1) * 128\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # No need to permute - we'll view the data differently\n",
    "        # We want (batch_size, time_points, leads) -> (batch_size, time_points, leads)\n",
    "        # This already has time_points as \"channels\" and leads as the \"sequence\"\n",
    "        \n",
    "        # Reshape to make time_points the channels dimension\n",
    "        x = x.permute(0, 1, 2)  # Now it's (batch_size, time_points, leads)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu3(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise Model (analyzing each lead over time):\n",
      "RowWiseECGModel(\n",
      "  (conv1): Conv1d(12, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=131072, out_features=64, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 8433729\n",
      "\n",
      "Column-wise Model (analyzing across leads at each time point):\n",
      "ColumnWiseECGModel(\n",
      "  (conv1): Conv1d(4096, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=384, out_features=64, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 835905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize both models\n",
    "row_model = RowWiseECGModel(input_channels=n_leads)\n",
    "row_model = row_model.to(device)\n",
    "\n",
    "col_model = ColumnWiseECGModel(input_channels=time_points)\n",
    "col_model = col_model.to(device)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Row-wise Model (analyzing each lead over time):\")\n",
    "print(row_model)\n",
    "row_params = sum(p.numel() for p in row_model.parameters())\n",
    "print(f\"Total parameters: {row_params}\")\n",
    "\n",
    "print(\"\\nColumn-wise Model (analyzing across leads at each time point):\")\n",
    "print(col_model)\n",
    "col_params = sum(p.numel() for p in col_model.parameters())\n",
    "print(f\"Total parameters: {col_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Row-wise Model for training\n"
     ]
    }
   ],
   "source": [
    "# Choose which model to use for training\n",
    "model_type = \"row\"  # Options: \"row\" or \"col\"\n",
    "\n",
    "if model_type == \"row\":\n",
    "    model = row_model\n",
    "    print(\"\\nUsing Row-wise Model for training\")\n",
    "else:\n",
    "    model = col_model\n",
    "    print(\"\\nUsing Column-wise Model for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Training both models\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train both models\n",
    "print(\"\\nStep 8: Training both models\")\n",
    "\n",
    "def train_model(model_name, model, train_loader, test_loader, device, criterion, learning_rate=0.001, num_epochs=20, patience=5):\n",
    "    print(f\"\\n----- Training {model_name} Model -----\")\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Tracking variables\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Print progress\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate epoch statistics\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate validation statistics\n",
    "        val_epoch_loss = val_loss / len(test_dataset)\n",
    "        val_epoch_acc = val_correct / val_total\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accs.append(val_epoch_acc)\n",
    "        \n",
    "        # Print epoch results\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - {epoch_time:.2f}s - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Loaded best model with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(f'{model_name} Model - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.title(f'{model_name} Model - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name.lower()}_training_history.png')\n",
    "    plt.close()\n",
    "    print(f\"{model_name} Model training history saved to '{model_name.lower()}_training_history.png'\")\n",
    "    \n",
    "    return model, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Training Row-wise Model -----\n",
      "Epoch [1/2], Batch [10/82], Loss: 0.5805\n",
      "Epoch [1/2], Batch [20/82], Loss: 0.7070\n",
      "Epoch [1/2], Batch [30/82], Loss: 0.7568\n",
      "Epoch [1/2], Batch [40/82], Loss: 0.7119\n",
      "Epoch [1/2], Batch [50/82], Loss: 0.7505\n",
      "Epoch [1/2], Batch [60/82], Loss: 0.7676\n",
      "Epoch [1/2], Batch [70/82], Loss: 0.6929\n",
      "Epoch [1/2], Batch [80/82], Loss: 0.7001\n",
      "Epoch [1/2] - 28.59s - Loss: 0.6520, Acc: 0.5989, Val Loss: 0.7044, Val Acc: 0.5413\n",
      "Epoch [2/2], Batch [10/82], Loss: 0.6405\n",
      "Epoch [2/2], Batch [20/82], Loss: 0.5038\n",
      "Epoch [2/2], Batch [30/82], Loss: 0.5979\n",
      "Epoch [2/2], Batch [40/82], Loss: 0.5628\n",
      "Epoch [2/2], Batch [50/82], Loss: 0.6798\n",
      "Epoch [2/2], Batch [60/82], Loss: 0.5417\n",
      "Epoch [2/2], Batch [70/82], Loss: 0.5118\n",
      "Epoch [2/2], Batch [80/82], Loss: 0.4663\n",
      "Epoch [2/2] - 41.22s - Loss: 0.5696, Acc: 0.7071, Val Loss: 0.7618, Val Acc: 0.5260\n",
      "Loaded best model with validation loss: 0.7044\n",
      "Row-wise Model training history saved to 'row-wise_training_history.png'\n",
      "\n",
      "----- Training Column-wise Model -----\n",
      "Epoch [1/2], Batch [10/82], Loss: 0.6993\n",
      "Epoch [1/2], Batch [20/82], Loss: 0.6829\n",
      "Epoch [1/2], Batch [30/82], Loss: 0.7417\n",
      "Epoch [1/2], Batch [40/82], Loss: 0.7112\n",
      "Epoch [1/2], Batch [50/82], Loss: 0.6337\n",
      "Epoch [1/2], Batch [60/82], Loss: 0.7554\n",
      "Epoch [1/2], Batch [70/82], Loss: 0.8021\n",
      "Epoch [1/2], Batch [80/82], Loss: 0.7175\n",
      "Epoch [1/2] - 2.81s - Loss: 0.7297, Acc: 0.4962, Val Loss: 0.6928, Val Acc: 0.5138\n",
      "Epoch [2/2], Batch [10/82], Loss: 0.6987\n",
      "Epoch [2/2], Batch [20/82], Loss: 0.6822\n",
      "Epoch [2/2], Batch [30/82], Loss: 0.6922\n",
      "Epoch [2/2], Batch [40/82], Loss: 0.6651\n",
      "Epoch [2/2], Batch [50/82], Loss: 0.6845\n",
      "Epoch [2/2], Batch [60/82], Loss: 0.6156\n",
      "Epoch [2/2], Batch [70/82], Loss: 0.6488\n",
      "Epoch [2/2], Batch [80/82], Loss: 0.6687\n",
      "Epoch [2/2] - 2.61s - Loss: 0.6822, Acc: 0.5713, Val Loss: 0.6992, Val Acc: 0.5076\n",
      "Loaded best model with validation loss: 0.6928\n",
      "Column-wise Model training history saved to 'column-wise_training_history.png'\n",
      "\n",
      "Model Performance Comparison:\n",
      "Row-wise Model Best Validation Loss: 0.7044\n",
      "Column-wise Model Best Validation Loss: 0.6928\n"
     ]
    }
   ],
   "source": [
    "# Train both models\n",
    "row_model_trained, row_best_loss = train_model(\"Row-wise\", row_model, train_loader, test_loader, device, criterion, learning_rate=0.001, num_epochs=2)\n",
    "col_model_trained, col_best_loss = train_model(\"Column-wise\", col_model, train_loader, test_loader, device, criterion, learning_rate=0.001, num_epochs=2)\n",
    "\n",
    "# Compare model performances\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(f\"Row-wise Model Best Validation Loss: {row_best_loss:.4f}\")\n",
    "print(f\"Column-wise Model Best Validation Loss: {col_best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-wise Model performed better and will be used for evaluation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if row_best_loss < col_best_loss:\n",
    "    better_model = row_model_trained\n",
    "    better_model_name = \"Row-wise\"\n",
    "    print(\"Row-wise Model performed better and will be used for evaluation\")\n",
    "else:\n",
    "    better_model = col_model_trained\n",
    "    better_model_name = \"Column-wise\"\n",
    "    print(\"Column-wise Model performed better and will be used for evaluation\")\n",
    "\n",
    "# Set the best model for further evaluation\n",
    "model = better_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to 'training_history.png'\n"
     ]
    }
   ],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(val_accs, label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()\n",
    "print(\"Training history saved to 'training_history.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9: Evaluating both models\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Evaluate both models\n",
    "print(\"\\nStep 9: Evaluating both models\")\n",
    "\n",
    "def evaluate_model(model_name, model, test_loader, device):\n",
    "    print(f\"\\n----- Evaluating {model_name} Model -----\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize arrays to store predictions and true labels\n",
    "    all_preds = []\n",
    "    all_preds_prob = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Test the model\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Convert to CPU and numpy for evaluation\n",
    "            preds_prob = outputs.cpu().numpy()\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            \n",
    "            # Append batch predictions to lists\n",
    "            all_preds.extend(preds)\n",
    "            all_preds_prob.extend(preds_prob)\n",
    "            all_labels.extend(labels)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_preds_prob = np.array(all_preds_prob).flatten()\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(f\"\\n{model_name} Model Classification Report:\")\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    print(report)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    print(f\"\\n{model_name} Model Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} Model - Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'{model_name.lower()}_roc_curve.png')\n",
    "    plt.close()\n",
    "    print(f\"ROC curve saved to '{model_name.lower()}_roc_curve.png'\")\n",
    "    \n",
    "    return all_preds, all_preds_prob, all_labels, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Evaluating Row-wise Model -----\n",
      "\n",
      "Row-wise Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.51      0.52       164\n",
      "         1.0       0.52      0.55      0.53       163\n",
      "\n",
      "    accuracy                           0.53       327\n",
      "   macro avg       0.53      0.53      0.53       327\n",
      "weighted avg       0.53      0.53      0.53       327\n",
      "\n",
      "\n",
      "Row-wise Model Confusion Matrix:\n",
      "[[83 81]\n",
      " [74 89]]\n",
      "ROC curve saved to 'row-wise_roc_curve.png'\n",
      "\n",
      "----- Evaluating Column-wise Model -----\n",
      "\n",
      "Column-wise Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.27      0.35       164\n",
      "         1.0       0.50      0.75      0.60       163\n",
      "\n",
      "    accuracy                           0.51       327\n",
      "   macro avg       0.51      0.51      0.48       327\n",
      "weighted avg       0.51      0.51      0.48       327\n",
      "\n",
      "\n",
      "Column-wise Model Confusion Matrix:\n",
      "[[ 44 120]\n",
      " [ 41 122]]\n",
      "ROC curve saved to 'column-wise_roc_curve.png'\n",
      "\n",
      "Model ROC AUC Comparison:\n",
      "Row-wise Model AUC: 0.5342\n",
      "Column-wise Model AUC: 0.5254\n",
      "Row-wise Model has better AUC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate both models\n",
    "row_preds, row_preds_prob, row_labels, row_auc = evaluate_model(\"Row-wise\", row_model_trained, test_loader, device)\n",
    "col_preds, col_preds_prob, col_labels, col_auc = evaluate_model(\"Column-wise\", col_model_trained, test_loader, device)\n",
    "\n",
    "# Compare model ROC AUCs\n",
    "print(\"\\nModel ROC AUC Comparison:\")\n",
    "print(f\"Row-wise Model AUC: {row_auc:.4f}\")\n",
    "print(f\"Column-wise Model AUC: {col_auc:.4f}\")\n",
    "\n",
    "if row_auc > col_auc:\n",
    "    print(\"Row-wise Model has better AUC\")\n",
    "    final_model_name = \"Row-wise\"\n",
    "    final_preds = row_preds\n",
    "    final_preds_prob = row_preds_prob\n",
    "    final_labels = row_labels\n",
    "else:\n",
    "    print(\"Column-wise Model has better AUC\")\n",
    "    final_model_name = \"Column-wise\"\n",
    "    final_preds = col_preds\n",
    "    final_preds_prob = col_preds_prob\n",
    "    final_labels = col_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d82762fec0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAKTCAYAAADR1X0mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8PklEQVR4nO3df4ychX0n/vfOGtuQ7JpvoDjjHYc6HDk2h0ovNkkBWVXSxBFBNIkawSmnkKakitXmkPGROwinJcGRrMtd+aZpgCQqJMqJcmiTppeTfA3W/eBHIRIgp6oCvvYSrmaXcSzTb7ybQE3Yne8f4128u7M/Zr2zM/Ps6yWNNvPs88x+Vh3Rffv5fD7TU6vVagEAACiQUrsLAAAAWGmCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDjr2l3AUkxOTubFF19MX19fenp62l0OAADQJrVaLePj49myZUtKpfnv23RF0HnxxRezdevWdpcBAAB0iBdeeCGVSmXe73dF0Onr60tS/2X6+/vbXA0AANAuY2Nj2bp163RGmE9XBJ2pdrX+/n5BBwAAWHSkxTICAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcJoOOo8++miuvfbabNmyJT09PfmLv/iLRa955JFHsn379mzcuDFvfetb89WvfnU5tQIAACxJ00HnF7/4RS677LJ85StfWdL5zz//fD7wgQ9k586dOXToUD772c/mpptuyne+852miwUAAFiKdc1ecPXVV+fqq69e8vlf/epX85a3vCVf+tKXkiSDg4N5+umn8x//43/M7/zO7zT74wEAABbV8hmdJ598Mrt27Zpx7P3vf3+efvrp/PKXv2x4zcmTJzM2NjbjAQAAtN7wcDI4mFQqrz/+ev2OVHsrefYNO9pd3pK1POgcPXo0mzdvnnFs8+bNee2113L8+PGG1+zfvz+bNm2afmzdurXVZQIAAEmGhpLDh5PR0dcf5/3yaMqTo/l//vFou8tbslXZutbT0zPjea1Wa3h8ym233ZYTJ05MP1544YWW1wgAACTj4/WvpVIyMFB/9J5KDaXe9tXVrKZndJr15je/OUePzkx+x44dy7p163Leeec1vGbDhg3ZsGFDq0sDAADmUS4nIyOnnlSSjCabL2hnRc1pedC54oor8l//63+dcezhhx/Ojh07ctZZZ7X6xwMAwJoxPFxvPZu6K3PNK8O5ZWwob5wcX/Jr/GCy/rW3mnrASZJqdUXrXA1NB52f//zn+T//5/9MP3/++efzwx/+MG9605vylre8JbfddltGR0fzrW99K0mye/fufOUrX8nevXvz+7//+3nyySdz33335cEHH1y53wIAAJier5myJ0O5OIfnv2Ahk0lGZx3r61tuaauu6aDz9NNP593vfvf087179yZJPv7xj+eb3/xmqtVqjhw5Mv39bdu25cCBA7n55ptz9913Z8uWLfnyl79stTQAAKyw0+dryuXk3Op4MplMpJRjpfKSX6enlPT3J+ecfdrBvr5k376VLbiFempTmwE62NjYWDZt2pQTJ06kv7+/3eUAAEB7zOpNe/mVZGwsqZ1qN5uYajs7FXRSrSaTk/WNAtMDN91tqdmg5TM6AADACpnVm3bOqcccs9vOuqjlbKUIOgAA0C1m9aZVqzPv4iQN2s66rOVspQg6AADQbU7tfr68Uv9AzwJ1pq2YVfnAUAAAgNUk6AAAAIUj6AAAAIUj6AAAQAd6cu9wfrxhMNXeyvRjYrSapL41ulKpf6UxywgAAKADXXD3UC569XDD7/1ssi+jp62PXoPboxcl6AAAQAc657X6KumJlHKsVJ4+/vNSX77Uvy8Dp9ZHr9Ht0YsSdAAAYKUND9c/3HPqc28aePmVZGwsqU02/v4Fk/W+tGOlcsoTM3dHf23FCi0uQQcAAFba0FByuHHb2ZRzTj0W8/I6fWnLIegAAMBKm7qTUyrVP9yzgWo1mTh1N6d3nhVhL6/ry7FP78tFLSix6AQdAABolXI5GRlp+K3LK8noaDIwMO8pSSLkLJOgAwAAzVjC/I29z+0n6AAAQDOWMH8zzd7nthF0AACgGUuYv0li73ObCToAALCQ2a1qU21pC8zfTF+yJ8mexi+ru621BB0AAFjIfK1qC7Sl6W5rP0EHAAAW0qhVbZG2NN1t7SfoAADAUizQqraCl7BC5vloIgAAYKmGh5PBwaRSqT/M37SfOzoAAHCGljHGQ4sJOgAAcIaWMcZDiwk6AABwulnrpGsvVtOTejva5ZXGlyxh4zSrTNABAIDTzepD6zn19WeTfRkdXfhSrWqdQ9ABAIDTzepDq1brIeeOnn0Z2DL/ZVrVOougAwAAjZzqQ7u8koyOJgNbtKV1E+ulAQCAwhF0AACAwhF0AACAwhF0AABY24aHk8HBpFKpP6Z2RdPVLCMAAGBtm7VOeppd0V1N0AEAYG2btU46iV3RBSDoAABAMr1OmmIwowMAABSOoAMAABSOoAMAABSOoAMAABSOoAMAABSOoAMAABSO9dIAABTX8HD9A0GnPiunkWp1wUtmfZsuIegAAFBcQ0PJ4cNLO7evb8FLTn2bLiHoAABQXFO3ZUql+geCzqevL9m3b95LTvs2XULQAQCg+MrlZGSk1ZfQQSwjAAAACkfQAQAACkfQAQAACkfQAQAACkfQAQAACkfQAQAACkfQAQAACsfn6AAAUBhP7h3OBXcP5ZzX6p/6ecFkNb1JqtXk8srSXqNabV19rB5BBwCAwrjg7qFc9OrhOcd/NtmX0dHmXquvb4WKoi0EHQAACmPqTs5ESjlWKidJfl7qy5f692Xg7KW/Tl9fsm9fKypktQg6AACsvOHhZGgoGR9f1R97wWS97+xYqZzyxMj08a+tahV0AkEHAICVNzSUHJ7bQtZqvae+/ryk72ytE3QAAFh5U3dySqWkXF61H1ut1udxvtS/z12cNU7QAQCgdcrlZGRk8fNWyOWVZHQ0Tc3jUEyCDgAAZ6bRPM6sHc2rNbJjNTRTBB0AAM7MQvM4p3Y0r/bIjtXQCDoAAJyZ+eZxTtvRvJojO1ZDkwg6AACslCXM46zyyA5rWKndBQAAAKw0QQcAACgcQQcAACgcQQcAACgcQQcAACgcQQcAACgcQQcAACgcQQcAACgcQQcAACicde0uAACA7jI8nAwNJePj9edPVZNykmo1ubzS+JpqddXKgySCDgAATRoaSg4ffv35xNTXyWR0dOFr+/paVhbMIOgAANCUqTs5pVJSLie91SSTSW8pGSjPf11fX7Jv36qUCIIOAADLUy4nIyNJKklGT3sOHcAyAgAAFjQ8nAwOJpVK/XHVi8N5NoN5qnrqgAEcOpA7OgAALGj2TM7nMpTBHE4mk5w+k2MAhw4i6AAAsKDZMznnVseTyaTWU0rPllNDOQZw6DCCDgBAQcxe+9zINa8M55axobxxcoGTZvnBZP1rb+prpJN6q1rPFkM5dC5BBwCgIGa3mDWyJ0O5OIucNB+tanQRQQcAoCBmt5g1MtV2NpFSjpUW2AU9S08p6e9Pzjn71AGtanQ4QQcAoGAWXPN8ahV070A5ZW1nFJigAwDQJRabwWm45Xn2RVZBs0YIOgAAXWIpMzjJrNGZ+S4yX0PBCToAAF1iKTM4c0ZnGl1kvoY1QNABAFhhS1nzvBxTXWcLzuDMZ1kXQfcSdAAAVthSW8yWS9cZLE7QAQBYYUtpMVsuXWewNIIOAECTlrr9rOXdYkvpkbNljTVK0AEAaNKytp+1s5BEvxtrjqADANCkZW0/a1chq1YMdBZBBwBgmTpmkVnHFAKdQ9ABADiNsRcoBkEHAOA0xl6gGAQdAIDTGHuBYhB0AIA1o5m2NGMv0N0EHQBgzdCWBmuHoAMArBna0mDtEHQAgDVHWxoUX6ndBQAAsETDw8ngYFKp1B/2XMO83NEBAOgW8w0ZGSiCOQQdAIBu0WjIyEARNLSs1rV77rkn27Zty8aNG7N9+/Y89thjC57/wAMP5LLLLss555yTcrmcT3ziE3nppZeWVTAAQCHNbktr9Ji9+3pkJHnuueQjH2lv7dCBmg46Dz30UPbs2ZPbb789hw4dys6dO3P11VfnyJEjDc9//PHHc8MNN+TGG2/Mj370owwPD+epp57KJz/5yTMuHgCgMKba0kZH539MTtbP1aoGi2q6de2uu+7KjTfeOB1UvvSlL+X73/9+7r333uzfv3/O+T/4wQ/yq7/6q7npppuSJNu2bcunPvWpfPGLX5z3Z5w8eTInT56cfj42NtZsmQAA3cXua1hRTd3RefXVV/PMM89k165dM47v2rUrTzzxRMNrrrzyyoyMjOTAgQOp1Wr56U9/mm9/+9u55ppr5v05+/fvz6ZNm6YfW7dubaZMAIDudXpbWqOHVjVYkqaCzvHjxzMxMZHNmzfPOL558+YcPXq04TVXXnllHnjggVx//fVZv3593vzmN+fcc8/Nn/zJn8z7c2677bacOHFi+vHCCy80UyYAsEYsZayl0YhLR7AqGlpqWVvXenp6Zjyv1Wpzjk159tlnc9NNN2VoaCjvf//7U61W85nPfCa7d+/Offfd1/CaDRs2ZMOGDcspDQBYQ+bbtryYjhhxsSoaWqqpoHP++eent7d3zt2bY8eOzbnLM2X//v256qqr8pnPfCZJ8mu/9mt5wxvekJ07d+YLX/hCygv1oAIALGCpYy2n65gRF6uioaWaCjrr16/P9u3bc/DgwXz4wx+ePn7w4MF88IMfbHjNyy+/nHXrZv6Y3t7eJPU7QQAASzE8XL8JMpUPkrnbljtWVxcP3anp1rW9e/fmYx/7WHbs2JErrrgiX//613PkyJHs3r07SX2+ZnR0NN/61reSJNdee21+//d/P/fee+9069qePXvyzne+M1u2bFnZ3wYAKKyF2tQ6vturq4uH7tR00Ln++uvz0ksv5c4770y1Ws2ll16aAwcO5MILL0ySVKvVGZ+p87u/+7sZHx/PV77ylfzrf/2vc+655+Y973lP/v2///cr91sAAIU3X5taV3R7dXXx0J16al3QPzY2NpZNmzblxIkT6e/vb3c5AEAbVCr1z8wcGOjCTq+uLh46y1KzQVPrpQEAALqBoAMAABSOoAMAABSOoAMAdKTh4WRwsD7eUqm8vo0ZYCma3roGALAa5tvIbBszsBSCDgDQkRptZLaNGVgqQQcA6AjDw/W7OFMBZ6pVrVzuwo3M8/0ywKoRdACAjlCoVrVC/TLQnQQdAKAjFKpVrVC/DHQnQQcA6Chd2ao2n0L9MtBdBB0AoOVmj6w0YowFWEmCDgDQcvONrDRijAVYCYIOANByjUZWGjHGAqwUQQcAOCPNtKUZWQFWi6ADAJwRbWlAJxJ0AIAzoi0N6ESCDgCwIrSlAZ1E0AEAaNZig0l2ZUPbCToAAM1a6mCSoSRoG0EHAKBZSxlMMpQEbSXoAAAsl8Ek6FildhcAAACw0gQdAACgcAQdAACgcMzoAACcbrHV0Yn10dAFBB0AgNMtdXV0Yn00dDBBBwDgdEtZHZ1YHw0dTtABAIprKW1os021pVkdDV1N0AEAiquZNrTZtKVBVxN0AIDiWmob2mza0qDrCToAQPFpQ4M1x+foAAAAhSPoAAAAhSPoAAAAhSPoAABNGR5OBgeTSqX+mNrG3BE6ujhgNVlGAAA0Zb6NzR2xjbmjiwNWk6ADADSl0cbmjtnG3NHFAatJ0AEAlmXVNzYPD9fv2EyFmUamWtWsk4Y1T9ABALrDfG1pjWhVgzVP0AEAukOjtrRGtKoBEXQAgG6jLQ1YAkEHAFjQk3uHc8HdQznntfodlR9M1o/3VpNUVrEQq6KBJgg6AMCCLrh7KBe92mA2ZjLJ6KqXY/4GWBJBBwBY0NSdnImUcqxUn43pKSX9/ck5Z69yMeZvgCUSdABgDVnKhubZplrVjpXKKU+YjQG6g6ADAGtIMxuaZ+sprWwtAK0k6ADAGrLUDc2n660mmay3qgF0C0EHANagpjY0V5KMtmEeB+AMuAkNAMw0PJwMDiaVSv1hrTPQhdzRAQBmmm+Qx1pnoIsIOgDATI0Geax1BrqMoAMANNbUIA9AZzGjAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFM66dhcAALTQ8HAyNJSMjydJnqomE0l6q0kq81xTra5WdQAtI+gAQJENDSWHD08/LU/9j8kko4tc29fXoqIAWk/QAYAiO3UnJ6VSUi6nWk0mJpPe+tP59fUl+/atSokArSDoAEBRzGpTS/J6G1q5nIyM5PJKMjqaDNSfAhSWoAMARTGrTW0GbWjAGiPoAEBRzGpTm6YNDViDBB0AKJqyvjQAQQcAutTskZynqvWtatVqcvk8q6NtjgbWCkEHALrU7JGciamvk/WFAwsxsgMUnaADAF1q9khObzXJqdXRAwusjjayA6wFgg4AdInZrWpXvTicz2Uo52b81AeB1vvSjOgACDoA0DVmt6p9LkMZzOFkMsnprWr60gAEHQDoFrNb1c6tjieTSa2nlJ4tp3rV9KUBJBF0AKDrTLemVZKMph5y9KoBzCDoAMBqmD1gswxPVeub1XqrqYccu6IB5iXoAMBqmD1gswzTi9TM5AAsStABgNUwe8BmGarV+mfk9J7+EmZyABoSdABgpTVqU5tqMzuD3c+XV+ofBDpgJAdgUYIOAKy0hdrUtJkBrApBBwBW2nxtatrMAFaNoAMAZ2p2q9oKtKkBcGYEHQA4U/O1qmlTA2gbQQcAzlSjVjVtagBtJegAwErRqgbQMQQdAGjWfDM5Z/ASS7GMHwOwZgk6ANCsFZjJWWgD9WKM/gAsTtABgGatwEzOfBuoF2P0B2BpBB0AWEijHrMVXB9trAegNQQdAFjIQj1mesgAOpagAwALma/HTA8ZQEcTdABgKfSYAXQVQQcAmrSc1dCzWRUN0FqCDgA06UxWQ89mzAegNQQdAGjScldDz2bMB6B1BB0AWCZjOwCdq9TuAgAAAFbasoLOPffck23btmXjxo3Zvn17HnvssQXPP3nyZG6//fZceOGF2bBhQy666KLcf//9yyoYAABgMU23rj300EPZs2dP7rnnnlx11VX52te+lquvvjrPPvts3vKWtzS85rrrrstPf/rT3Hffffkn/+Sf5NixY3nttdfOuHgAAIBGemq1Wq2ZC971rnflHe94R+69997pY4ODg/nQhz6U/fv3zzn/L//yL/Mv/sW/yE9+8pO86U1vWtLPOHnyZE6ePDn9fGxsLFu3bs2JEyfS39/fTLkArCUrsfd5tmo1mZxMBgamB3IqlWR0dMYhAFbJ2NhYNm3atGg2aOqOzquvvppnnnkmt95664zju3btyhNPPNHwmu9973vZsWNHvvjFL+Y//af/lDe84Q357d/+7ezbty9nn312w2v279+fz3/+882UBgAru/d5NnugAbpKU0Hn+PHjmZiYyObNm2cc37x5c44ePdrwmp/85Cd5/PHHs3Hjxnz3u9/N8ePH8wd/8Af5h3/4h3nndG677bbs3bt3+vnUHR0AWNBK7X2ezR5ogK6zrPXSPT09M57XarU5x6ZMTk6mp6cnDzzwQDZt2pQkueuuu/KRj3wkd999d8O7Ohs2bMiGDRuWUxoA2PsMQHNb184///z09vbOuXtz7NixOXd5ppTL5QwMDEyHnKQ+01Or1TLi/wkBAAAt0FTQWb9+fbZv356DBw/OOH7w4MFceeWVDa+56qqr8uKLL+bnP//59LG//du/TalUSqVSWUbJAAAAC2v6c3T27t2bP/3TP83999+f5557LjfffHOOHDmS3bt3J6nP19xwww3T53/0ox/Neeedl0984hN59tln8+ijj+Yzn/lMfu/3fm/eZQQA0C7Dw8ngYH2z2nyParXdVQKwmKZndK6//vq89NJLufPOO1OtVnPppZfmwIEDufDCC5Mk1Wo1R44cmT7/jW98Yw4ePJh/9a/+VXbs2JHzzjsv1113Xb7whS+s3G8BACukmcVtFrEBdK6mP0enHZa6KxuANW4FPuBm6iUWW9w2tYjtIx9ZZq0ALEtLPkcHANYKi9sAupugA8CaMjxcb0+b+sid2czfABSDoAPAmrLUGRzzNwDdTdABYE2ZupOz0AzO1PwNAN1L0AGge83uQ5vVd9aoTW3qFDM4AMUm6ADQvebrQzvVd7ZQm5rWNIBiE3QA6F6N+tBO6zubr01NaxpA8Qk6AHS/RfrQtKkBrD2CDgCdYbG9z43YBQ3APAQdADrDUvc+N2LgBoBZBB0AOsNS9j43YuAGgAYEHQA6SxMDNdPdbnuS7Jn7fZ1tAGuXoANA11pqt5vONoC1R9ABoGstpdtNZxvA2iToAND1rI8GYLZSuwsAYA0aHk4GB5NK5fXHIgM1y7gEgDXMHR0AVt9CwzXzDNQs4xIA1jBBB4DVN99wzQIDNcu4BIA1TNABoH0WGK6ZXh19KuBMtamZxwFgKQQdADrSfK1q2tQAWApBB4CO1KhVTZsaAEsl6ADQ0bSqAbAc1ksDAACFI+gAAACFI+gAAACFY0YHgDM2exX0Yp6qJuXUV0ZfXml8ztQ6aQBYDkEHgDM23yro+UxMfZ1MRkcXPtc6aQCWQ9AB4Iw1WgW9kN5qksmkt5QMLHC+ddIALJegA8CKWfIq6EqSUaujAWgdywgAAIDCEXQAAIDCEXQAAIDCEXQAaL3h4WRwMKlU6g+7owFoMcsIAGi9+fZP2x0NQIsIOgC0XqP903ZHA9BCgg4Aq8c+aQBWiRkdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcKyXBuCMXfPKcPZkKOdWx5NKgxOq1VWvCYC1TdAB4IzdMjaUi3M4mUwyusCJfX2rVRIAa5ygA8AZe+PkeJJkIqX0DpQbn9TXl+zbt4pVAbCWCToArJhjpXLKIyPtLgMABB2AtWx4OBkaSsbH5z/nmleGc8vY0PRdm0YumDSDA0BnEXQA1rChoeTw4YXP2ZNT8zdL8PI6MzgAdAZBB2ANm7qTUyol5XlGa86tjieT9fmbY6V5Tko95Bz79L5c1II6AaBZgg7AWjKrV+2pajKRpDfJ/BGm3pbWO7D4/I2QA0CnEHQA1pJZvWrT4WaxtdCJ1dAAdBVBB2AtmdWrVq0mE5NJ7wKta0mshgag6wg6AEU2e61a9dR2tHI5GRnJ5ZVkdDQZqD8FgMIQdACKbL61atrQACg4QQegyBqtVdOGBsAaIOgArAVlvWkArC2CDkBRzJ7HSVJ7sZqe1EdzLq/MvWRqZAcAikbQASiKBvM4Pae+/myyL6MLrI82sgNA0Qg6AEXRYB6nWq2HnDt69mVgS+PLjOwAUESCDkDRnDaPM70+eosRHQDWllK7CwAAAFhpgg4AAFA4gg4AAFA4gg5Al3py73B+vGEw1d5Kqr2VTIzWd0VXq0mlUn9YHw3AWmUZAUCXuuDuoVz06uE5xxutkrY+GoC1RtAB6FLnvFZfJz2RUo6V6uukf17qy5f692Xg7NfPsz4agLVI0AHoEk/uHc4Fdw9NB5wLJut9acdK5ZQnXt8d/bW2VAcAnUXQAegS87WqvbxOXxoAzCboAHSJRq1qL6/ry7FP78tF7SwMADqQoAPQZWa3qgk5ADCXoAPQBsPDydBQMj4+/znXvDKcW8aG8sbJmTM5AMDiBB2ANhgaSg7PHbeZYU+GcnHM5ADAcgg6AG0wdSenVErK5cbnnFsdTybN5ADAcgg6AKtgdqta9VQXWrmcjIw0OKF+VpKkd6Cc8oiZHABohqADsArma1Xr61vkhBknAQBLJegArIJGrWp9fcm+fQucMOckAGCpBB2AFdaoC21Oq9p8Fj0BAFgKQQdghelCA4D2E3QAVpguNABoP0EHoEV0oQFA+5TaXQAAAMBKE3QAAIDCEXQAAIDCEXQA2mF4OBkcTCqV+mNq/zQAsCIsIwBoh/l2UNs/DQArQtABaIdGO6jtnwaAFSPoALSTHdQA0BKCDsAKu+aV4ezJUM6tjieVeU4ykwMALSXoAKywW8aGcnEOJ5NJRhc52UwOALSEoAOwwt44WZ+/mUgpvQPl+U80kwMALSPoALTIsVI5ZfM3ANAWPkcHAAAoHEEHAAAoHEEHAAAoHDM6AIsZHk6Ghl7/kM9ZXn4lGRtLapP15xdMWh0NAO0m6AAsZmgoOXx43m+fc+ox28vrrI4GgHYRdAAWM3Unp1RKynPXRVerycSpuzm9pxqCX17Xl2Of3peLVqlEAGAmQQdY2xZpS0tSTzJJPeQ0WBd9eSUZHU0GBmZ+W8gBgPYRdIC1bZG2tBn6tKIBQLcQdIC1bZG2tGl9fcm+fatTEwBwxgQdgGTetjQAoDst63N07rnnnmzbti0bN27M9u3b89hjjy3pur/6q7/KunXr8uu//uvL+bEAAABL0nTQeeihh7Jnz57cfvvtOXToUHbu3Jmrr746R44cWfC6EydO5IYbbshv/dZvLbtYAACApWg66Nx111258cYb88lPfjKDg4P50pe+lK1bt+bee+9d8LpPfepT+ehHP5orrrhi0Z9x8uTJjI2NzXgAAAAsVVNB59VXX80zzzyTXbt2zTi+a9euPPHEE/Ne941vfCM//vGPc8cddyzp5+zfvz+bNm2afmzdurWZMgEAgDWuqaBz/PjxTExMZPPmzTOOb968OUePHm14zd/93d/l1ltvzQMPPJB165a2++C2227LiRMnph8vvPBCM2UCAABr3LK2rvX09Mx4XqvV5hxLkomJiXz0ox/N5z//+bztbW9b8utv2LAhGzZsWE5pAAAAzQWd888/P729vXPu3hw7dmzOXZ4kGR8fz9NPP51Dhw7l05/+dJJkcnIytVot69aty8MPP5z3vOc9Z1A+QJOGh+sfEjr1+TnVanvrAQBaoqmgs379+mzfvj0HDx7Mhz/84enjBw8ezAc/+ME55/f39+dv/uZvZhy755578j/+x//It7/97Wzbtm2ZZQMs09BQcvjw3ON9fatfCwDQMk23ru3duzcf+9jHsmPHjlxxxRX5+te/niNHjmT37t1J6vM1o6Oj+da3vpVSqZRLL710xvUXXHBBNm7cOOc4wKqYupNTKtU/JDSph5x9+9pXEwCw4poOOtdff31eeuml3HnnnalWq7n00ktz4MCBXHjhhUmSarW66GfqALRduZyMjLS7CgCgRXpqtVqt3UUsZmxsLJs2bcqJEyfS39/f7nKAblapJKOjycBAw6Aze4RnKarVZHJy3pcEAFbQUrPBsrauARTVfCM8S2HMBwA6h6ADcJpGIzxLYcwHADqLoAOsKS+/kpyTervZ5ZW535/aNm2EBwC6m6ADrCljY/WgMzFZH9WZjzY0AOhugg6wptQmX//fAwONz9GGBgDdT9AB1qTektY0ACiyUrsLAAAAWGmCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDiCDgAAUDjr2l0AwEoZHk6GhpLx8fnP+cHk6tUDALSPoAMUxtBQcvjw0s7tcT8bAApN0AEKY+pOTqmUlMuNz+mtJplM+vtXrSwAoA38mybQtYaHk8HBpFKpP6rV+vFyORkZSUb+3+GM9A1mJJXpRzn1k845u42FAwAt544O0LXma1Xr61vkhBknAQBFJOgAXatRq1pfX7Jv3wInzDkJACgiQQfoelOtass/AQAoGjM6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6QFcYHk4GB5NK5fVHtbrISXNOAADWinXtLgBgKYaGksOHG3+vr2+Rk6ZPAADWCkEH6Arj4/WvpVJSLr9+vK8v2bdvgZNmnAAArBWCDtBVyuVkZGQlTgIAikzQAVbc8HC9i2zqBstKaDhuM/sHmckBAE4RdIAVt9A8zZmaMW5jJgcAmIegA6y4+eZpztSccRszOQDAPAQd4IzN10G2aqMyZnIAgFkEHeCM6SADADqNoAOcMR1kAECnEXSAFaODDADoFKV2FwAAALDSBB0AAKBwBB0AAKBwBB0AAKBwBB0AAKBwBB0AAKBwrJcGZhgern8A6NRn4yxFtdqmQlrygwGAIhB0gBmGhpLDh5d3bV9fmwpZ0R8MABSBoAPMMHUDpVSqfwDoUvX1Jfv2taGQFf/BAEARCDpAQ+VyMjLS7irSQYUAAN1E0AHaY7EZHPM3AMAZEHSA9ljqDI75GwBgGQQdoD2WMoNj/gYAWCZBB2i9Rm1qU61pZnAAgBYQdIDWW6hNTWsaANACgg7QevO1qWlNAwBaRNABVo82NQBglZTaXQDQXsPDyeBgUqnUHyuy1bklLwoAsHTu6MAaN9/4zBmNzrTkRQEAlk7QgTWu0fjMGY/OtORFAQCWTtCBNWTVtzybyQEA2kTQgTXElmcAYK0QdGANseUZAFgrBB1Yg3SUAQBFZ700AABQOIIOAABQOIIOAABQOGZ0oMBmr5OeWiXd1EXLsaQfBADQOoIOFNh866QXXCW90A7qZtlZDQC0iaADBdZonfSiq6Tn20HdLDurAYA2EnSgQOZrVVvWOmk7qAGALiboQIEsq1UNAKCABB0okGW1qgEAFJCgAwWk6wwAWOsEHehQy9nyvOhW56W8qNXQAEABCDrQoc5ky/O8MznNvKjBHgCgiwk60KGWu+V5wZmcpb6owR4AoMsJOtDhzmjeZkX3TQMAdA9BB4rMvmkAYI0SdKDI7JsGANYoQQfWAq1qAMAaU2p3AQAAACtN0AEAAApH0AEAAApH0AEAAApH0AEAAApH0AEAAApH0AEAAArH5+hAh7rmleHsyVDOrY4nlWW+SLW6ojUBAHQLQQc61C1jQ7k4h5PJJKNn+GJ9fStREgBA1xB0oEO9cXI8STKRUnoHyst/ob6+ZN++FaoKAKA7CDrQ4Y6VyimPjLS7DACArmIZAQAAUDiCDgAAUDiCDnSA4eFkcDCpVF5/TEy2uyoAgO5lRgc6wNBQcvhw4+/1+OcIAICmCTrQAcbrC9ZSKiXlUwvWeqtJJpP+/raVBQDQtZb1b8X33HNPtm3blo0bN2b79u157LHH5j33z//8z/O+970vv/Irv5L+/v5cccUV+f73v7/sgqHIyuVkZKT+mAo855zd3poAALpR00HnoYceyp49e3L77bfn0KFD2blzZ66++uocOXKk4fmPPvpo3ve+9+XAgQN55pln8u53vzvXXnttDh06dMbFQ7eaPZNTrba7IgCAYump1Wq1Zi5417velXe84x259957p48NDg7mQx/6UPbv37+k1/hn/+yf5frrr8/Q0FDD7588eTInT56cfj42NpatW7fmxIkT6dfHQwEMDjaeybnkkuS55049qVSS0dFkYKB+iwcAgIyNjWXTpk2LZoOm7ui8+uqreeaZZ7Jr164Zx3ft2pUnnnhiSa8xOTmZ8fHxvOlNb5r3nP3792fTpk3Tj61btzZTJnS802dyBgbqj0suSfbta29dAABF0VTQOX78eCYmJrJ58+YZxzdv3pyjR48u6TX+6I/+KL/4xS9y3XXXzXvObbfdlhMnTkw/XnjhhWbKhI53zSvDeTaDGUll+vHceCUf2VPRzwYAsAKWtXWtp6dnxvNarTbnWCMPPvhgPve5z+W//Jf/kgsuuGDe8zZs2JANGzYspzToCreMDeXiHE4mk4wucnJf32qUBABQKE0FnfPPPz+9vb1z7t4cO3Zszl2e2R566KHceOONGR4eznvf+97mK4UCeeNkvXdtIqX0DpTnP7GvTz8bAMAyNBV01q9fn+3bt+fgwYP58Ic/PH384MGD+eAHPzjvdQ8++GB+7/d+Lw8++GCuueaa5VcLBXOsVE7ZogEAgBXXdOva3r1787GPfSw7duzIFVdcka9//es5cuRIdu/enaQ+XzM6OppvfetbSeoh54Ybbsgf//Ef5zd+4zem7wadffbZ2bRp0wr+KgAAAHVNB53rr78+L730Uu68885Uq9VceumlOXDgQC688MIkSbVanfGZOl/72tfy2muv5Q//8A/zh3/4h9PHP/7xj+eb3/zmmf8GAAAAszT9OTrtsNRd2dAtqr2VlCdHUy0NpDyhdQ0AYKmWmg2WtXUN1rTh4WRo6PUPw2ng5VeSsbGkNtn4+xdMWh0NANBKgg40a2goOXx4wVPOOfVYzMvrrI4GAGgFQQeaNXUnp1RKyo1XQ1erycSpuzm983ws78vr+nLs0/tyUQtKBABY6wQdWK5yOZlnNfTllWR0NBkYmPeUJBFyAABaZJ5/awamDQ8ng4NJpVJ/VM3XAAB0Ond0YDHzzeT0ma8BAOhUgg4sptFMTl9fsm9f+2oCAGBBgg6crtHq6KlWtXlmcha6BACA9hB04HQLrY6ep1VtGZcAANBigg6cbr7V0Qu0qi3jEgAAWkzQgUYWWB29gpcAANAi1kuztlkdDQBQSO7osLZZHQ0AUEiCDmub1dEAAIUk6EDS1IDN7HXSut0AADqPoANN0u0GAND5BB1okm43AIDOJ+jQvWb3kC3HGfSdWScNANC5BB2613w9ZMuh7wwAoFAEHbpXox6y5dB3BgBQOIIO3U8PGQAAswg6dI3ZIzlPVZNy6mM2l1dWrw7rpAEAOp+gQ9eYPZIzMfV1MhkdXf16jPUAAHQuQYeuMXskp7eaZDLpLSUDZzCisxzGegAAOpugQ9eZHsmpJBk1ogMAwFyldhcAAACw0gQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcAQdAACgcNa1uwDWpuHhZGgoGR9f+jXVauvqAQCgWAQd2mJoKDl8eHnX9vWtbC0AABSPoENbTN3JKZWScnnp1/X1Jfv2taYmAACKQ9Ch9Rr0qT1VTSaS9CZpIuck40n2nHroZQMAYB6CDq3XoE9tOtxMJhk9w9fXywYAwCyCDq3XoE+tWk0mJpPeJlvX5tDLBgBAA4IOLffyK8k5Saop5/KMJEmqqd/MGSgnIyPtrA4AgCISdGi5sbF60JmYTEZntanpOgMAoBUEHVquNvn6/x4YeP1/6zoDAKBVBB1WTW9JmxoAAKuj1O4CAAAAVpqgAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI6gAwAAFI7P0eHMDQ8nQ0PJ+HiS5OVXkrGx1z8o9ILJahuLAwBgLRJ0OHNDQ8nhw9NPzzn1mO3ldX2rVhIAAGuboMOZO3UnJ6VSUi6nWk0mTt3N6T3VHPnyur4c+/S+XNSeCgEAWGMEHZo3q1Ut1VOtaeVyMjKSyyvJ6GgyMJCMjLx+mZADAMBqEXRo3qxWtWl9WtMAAOgMgg7Nm9WqlqQecvbta19NAABwGkGH5TvVqgYAAJ3G5+hwxoaHk8HBpFKpP6q2SQMA0Gbu6HDGjOwAANBpBB3OmJEdAAA6jaDDwmavkk5Se7GantRb1C6vzNkuDQAAbSfosLAGfWk9p77+bLIvo6OvH9eqBgBApxB0WFiDvrRqtR5y7ujZl4Et9W9rVQMAoJMIOsw0q1Vtuk0t5Vyeel9aNclkkoEtWtUAAOhMgg4zzWpVm69NLdGqBgBA5xJ0mGlWq1qjNrVEqxoAAJ1N0KGxUyvULq8ko6Pa1AAA6C6CzhrSYFP0HE9Vk3Lmro4GAIBuIuisIQ02Rc8xMfV1MlZHAwDQtQSdNaTBpug5ek+tVOstJQOnzjGPAwBAtxF0CmR2a9o1rwznlrGhvHGyfuAHk/Xjvam3pzVW71U7NaIDAABdSdApkNmtaXsylIvToFdtMsno3MMz6FUDAKCLCToFMrs17dzqeDKZTKSUY6X6PZyeUtLfn5xz9gIvpFcNAIAuJ+gU0HTbWSXJaNI7UE5ZHxoAAGuIoNMllrIa2ipoAACoE3S6xFJWQ08xXgMAwFon6HSJpayGTozXAABAIuh0rNmtalNtadY+AwDA4gSdDjVfq5q2NAAAWJyg06EatappSwMAgKURdDqcVjUAAGheqd0FsIKGh5PBwaRSqT/smwYAYI1yR6dIDPYAAEASQadYDPYAAEASQaeYDPYAALDGmdEBAAAKR9ABAAAKR9ABAAAKx4xOGwwP1xekTe0OaOSqF4fzuQzl3Op4UlniC1snDQAASQSdtphvC/TpPpehDOZwMplktMkfYJ00AABrnKDTBo22QM92bnU8mUxqPaX0bJnnpEaskwYAAEGnJRbpTXuqmkwk6U0yf4Spt6H1bLEqGgAAmiXotMIivWnT4WYpbWna0AAAoGmCTiss0ptWrSYTk0nvAq1rSbShAQDAMgk6TZrdlXbNK8O5ZWwob5x8vU3tgslqepNUU87lmdt2Vk39Zs6ArjQAAGgJQadJs7vS9mQoF6dxm9rPJvsyukBrmq40AABoDUGnSbO70qa2o02klGOl1/vQfl7qy5f692Xg7MavoysNAABaR9BZpvJU21klyWjSO1BOeVYf2tfaUhkAAFBqdwEAAAArbVlB55577sm2bduycePGbN++PY899tiC5z/yyCPZvn17Nm7cmLe+9a356le/uqxiAQAAlqLpoPPQQw9lz549uf3223Po0KHs3LkzV199dY4cOdLw/Oeffz4f+MAHsnPnzhw6dCif/exnc9NNN+U73/nOGRcPAADQSE+tVqs1c8G73vWuvOMd78i99947fWxwcDAf+tCHsn///jnn/9t/+2/zve99L88999z0sd27d+ev//qv8+STTzb8GSdPnszJkyenn4+NjWXr1q05ceJE+vv7myl3xf31+h0575dHX/8MnGo1mZxMBgbsigYAgBYbGxvLpk2bFs0GTd3RefXVV/PMM89k165dM47v2rUrTzzxRMNrnnzyyTnnv//978/TTz+dX/7ylw2v2b9/fzZt2jT92Lp1azNlttQFE0dTyWjKk6PJ6Gg95CR2RQMAQAdpKugcP348ExMT2bx584zjmzdvztGjRxtec/To0Ybnv/baazl+/HjDa2677bacOHFi+vHCCy80U2ZL/X8b35xqaSA/PWugfhdnYCC55BK7ogEAoIMsa710T0/PjOe1Wm3OscXOb3R8yoYNG7Jhw4bllNZyb//F0+0uAQAAWERTd3TOP//89Pb2zrl7c+zYsTl3baa8+c1vbnj+unXrct555zVZLgAAwOKaCjrr16/P9u3bc/DgwRnHDx48mCuvvLLhNVdcccWc8x9++OHs2LEjZ511VpPlAgAALK7p9dJ79+7Nn/7pn+b+++/Pc889l5tvvjlHjhzJ7t27k9Tna2644Ybp83fv3p2///u/z969e/Pcc8/l/vvvz3333Zdbbrll5X4LAACA0zQ9o3P99dfnpZdeyp133plqtZpLL700Bw4cyIUXXpgkqVarMz5TZ9u2bTlw4EBuvvnm3H333dmyZUu+/OUv53d+53dW7rcAAAA4TdOfo9MOS92VDQAAFFtLPkcHAACgGwg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4Qg6AABA4axrdwFLUavVkiRjY2NtrgQAAGinqUwwlRHm0xVBZ3x8PEmydevWNlcCAAB0gvHx8WzatGne7/fUFotCHWBycjIvvvhi+vr60tPT09ZaxsbGsnXr1rzwwgvp7+9vay10B+8ZmuU9Q7O8Z2iW9wzN6qT3TK1Wy/j4eLZs2ZJSaf5JnK64o1MqlVKpVNpdxgz9/f1t/z8y3cV7hmZ5z9As7xma5T1DszrlPbPQnZwplhEAAACFI+gAAACFI+g0acOGDbnjjjuyYcOGdpdCl/CeoVneMzTLe4Zmec/QrG58z3TFMgIAAIBmuKMDAAAUjqADAAAUjqADAAAUjqADAAAUjqADAAAUjqDTwD333JNt27Zl48aN2b59ex577LEFz3/kkUeyffv2bNy4MW9961vz1a9+dZUqpVM085758z//87zvfe/Lr/zKr6S/vz9XXHFFvv/9769itXSCZv87M+Wv/uqvsm7duvz6r/96awuk4zT7njl58mRuv/32XHjhhdmwYUMuuuii3H///atULZ2g2ffMAw88kMsuuyznnHNOyuVyPvGJT+Sll15apWppp0cffTTXXntttmzZkp6envzFX/zFotd0w9+/gs4sDz30UPbs2ZPbb789hw4dys6dO3P11VfnyJEjDc9//vnn84EPfCA7d+7MoUOH8tnPfjY33XRTvvOd76xy5bRLs++ZRx99NO973/ty4MCBPPPMM3n3u9+da6+9NocOHVrlymmXZt8zU06cOJEbbrghv/Vbv7VKldIplvOeue666/Lf//t/z3333Zf//b//dx588MFccsklq1g17dTse+bxxx/PDTfckBtvvDE/+tGPMjw8nKeeeiqf/OQnV7ly2uEXv/hFLrvssnzlK19Z0vld8/dvjRne+c531nbv3j3j2CWXXFK79dZbG57/b/7Nv6ldcsklM4596lOfqv3Gb/xGy2qkszT7nmnk7W9/e+3zn//8SpdGh1rue+b666+v/bt/9+9qd9xxR+2yyy5rYYV0mmbfM//tv/232qZNm2ovvfTSapRHB2r2PfMf/sN/qL31rW+dcezLX/5yrVKptKxGOlOS2ne/+90Fz+mWv3/d0TnNq6++mmeeeSa7du2acXzXrl154oknGl7z5JNPzjn//e9/f55++un88pe/bFmtdIblvGdmm5yczPj4eN70pje1okQ6zHLfM9/4xjfy4x//OHfccUerS6TDLOc9873vfS87duzIF7/4xQwMDORtb3tbbrnllrzyyiurUTJttpz3zJVXXpmRkZEcOHAgtVotP/3pT/Ptb38711xzzWqUTJfplr9/17W7gE5y/PjxTExMZPPmzTOOb968OUePHm14zdGjRxue/9prr+X48eMpl8stq5f2W857ZrY/+qM/yi9+8Ytcd911rSiRDrOc98zf/d3f5dZbb81jjz2Wdev8Z3utWc575ic/+Ukef/zxbNy4Md/97ndz/Pjx/MEf/EH+4R/+wZzOGrCc98yVV16ZBx54INdff33+8R//Ma+99lp++7d/O3/yJ3+yGiXTZbrl7193dBro6emZ8bxWq805ttj5jY5TXM2+Z6Y8+OCD+dznPpeHHnooF1xwQavKowMt9T0zMTGRj370o/n85z+ft73tbatVHh2omf/OTE5OpqenJw888EDe+c535gMf+EDuuuuufPOb33RXZw1p5j3z7LPP5qabbsrQ0FCeeeaZ/OVf/mWef/757N69ezVKpQt1w9+//mnwNOeff356e3vn/GvHsWPH5qTWKW9+85sbnr9u3bqcd955LauVzrCc98yUhx56KDfeeGOGh4fz3ve+t5Vl0kGafc+Mj4/n6aefzqFDh/LpT386Sf2P2FqtlnXr1uXhhx/Oe97znlWpnfZYzn9nyuVyBgYGsmnTpuljg4ODqdVqGRkZycUXX9zSmmmv5bxn9u/fn6uuuiqf+cxnkiS/9mu/lje84Q3ZuXNnvvCFL3TMv9DTGbrl7193dE6zfv36bN++PQcPHpxx/ODBg7nyyisbXnPFFVfMOf/hhx/Ojh07ctZZZ7WsVjrDct4zSf1Ozu/+7u/mz/7sz/Q/rzHNvmf6+/vzN3/zN/nhD384/di9e3f+6T/9p/nhD3+Yd73rXatVOm2ynP/OXHXVVXnxxRfz85//fPrY3/7t36ZUKqVSqbS0XtpvOe+Zl19+OaXSzD8Le3t7k7z+L/UwpWv+/m3TEoSO9Z//83+unXXWWbX77ruv9uyzz9b27NlTe8Mb3lD7v//3/9ZqtVrt1ltvrX3sYx+bPv8nP/lJ7ZxzzqndfPPNtWeffbZ233331c4666zat7/97Xb9CqyyZt8zf/Znf1Zbt25d7e67765Vq9Xpx89+9rN2/QqssmbfM7PZurb2NPueGR8fr1UqldpHPvKR2o9+9KPaI488Urv44otrn/zkJ9v1K7DKmn3PfOMb36itW7euds8999R+/OMf1x5//PHajh07au985zvb9SuwisbHx2uHDh2qHTp0qJakdtddd9UOHTpU+/u///tarda9f/8KOg3cfffdtQsvvLC2fv362jve8Y7aI488Mv29j3/847Xf/M3fnHH+//pf/6v2z//5P6+tX7++9qu/+qu1e++9d5Urpt2aec/85m/+Zi3JnMfHP/7x1S+ctmn2vzOnE3TWpmbfM88991ztve99b+3ss8+uVSqV2t69e2svv/zyKldNOzX7nvnyl79ce/vb3147++yza+VyufYv/+W/rI2MjKxy1bTD//yf/3PBv0269e/fnlrN/UgAAKBYzOgAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACFI+gAAACF8/8DPQOheCxVp9sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a combined ROC curve plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Row-wise model ROC\n",
    "fpr_row, tpr_row, _ = roc_curve(row_labels, row_preds_prob)\n",
    "plt.plot(fpr_row, tpr_row, color='blue', lw=2, label=f'Row-wise (AUC = {row_auc:.3f})')\n",
    "\n",
    "# Column-wise model ROC\n",
    "fpr_col, tpr_col, _ = roc_curve(col_labels, col_preds_prob)\n",
    "plt.plot(fpr_col, tpr_col, color='red', lw=2, label=f'Column-wise (AUC = {col_auc:.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjhha\\AppData\\Local\\Temp\\ipykernel_18776\\2405286142.py:9: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(loc=\"lower right\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined ROC curve saved to 'combined_roc_curve.png'\n"
     ]
    }
   ],
   "source": [
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model Comparison - Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('combined_roc_curve.png')\n",
    "plt.close()\n",
    "print(\"Combined ROC curve saved to 'combined_roc_curve.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10: Saving results\n",
      "Row-wise model saved to 'chagas_row_model.pth'\n",
      "Column-wise model saved to 'chagas_col_model.pth'\n",
      "\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.44      0.49       164\n",
      "         1.0       0.53      0.64      0.58       163\n",
      "\n",
      "    accuracy                           0.54       327\n",
      "   macro avg       0.54      0.54      0.54       327\n",
      "weighted avg       0.54      0.54      0.54       327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10: Save models and results\n",
    "print(\"\\nStep 10: Saving results\")\n",
    "\n",
    "# Save both PyTorch models\n",
    "torch.save(row_model_trained.state_dict(), 'chagas_row_model.pth')\n",
    "print(\"Row-wise model saved to 'chagas_row_model.pth'\")\n",
    "\n",
    "torch.save(col_model_trained.state_dict(), 'chagas_col_model.pth')\n",
    "print(\"Column-wise model saved to 'chagas_col_model.pth'\")\n",
    "\n",
    "# Map back to original exam IDs\n",
    "original_test_ids = [original_ids[i] for i in test_indices]\n",
    "\n",
    "# Create DataFrame with predictions from both models\n",
    "predictions_df = pd.DataFrame({\n",
    "    'exam_id': original_test_ids,\n",
    "    'true_chagas': final_labels,\n",
    "    'row_predicted_prob': row_preds_prob,\n",
    "    'row_predicted_chagas': row_preds,\n",
    "    'col_predicted_prob': col_preds_prob,\n",
    "    'col_predicted_chagas': col_preds\n",
    "})\n",
    "\n",
    "# Add ensemble prediction (average of both models)\n",
    "predictions_df['ensemble_prob'] = (predictions_df['row_predicted_prob'] + predictions_df['col_predicted_prob']) / 2\n",
    "predictions_df['ensemble_chagas'] = (predictions_df['ensemble_prob'] > 0.5).astype(int)\n",
    "\n",
    "# Calculate ensemble metrics\n",
    "print(\"\\nEnsemble Model Classification Report:\")\n",
    "print(classification_report(predictions_df['true_chagas'], predictions_df['ensemble_chagas']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model AUC: 0.5362\n",
      "Ensemble ROC curve saved to 'ensemble_roc_curve.png'\n"
     ]
    }
   ],
   "source": [
    "# Calculate ensemble ROC AUC\n",
    "fpr_ensemble, tpr_ensemble, _ = roc_curve(predictions_df['true_chagas'], predictions_df['ensemble_prob'])\n",
    "ensemble_auc = auc(fpr_ensemble, tpr_ensemble)\n",
    "print(f\"Ensemble Model AUC: {ensemble_auc:.4f}\")\n",
    "\n",
    "# Add ensemble to the ROC curve comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Row-wise model ROC\n",
    "plt.plot(fpr_row, tpr_row, color='blue', lw=2, label=f'Row-wise (AUC = {row_auc:.3f})')\n",
    "# Column-wise model ROC\n",
    "plt.plot(fpr_col, tpr_col, color='red', lw=2, label=f'Column-wise (AUC = {col_auc:.3f})')\n",
    "# Ensemble model ROC\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, color='green', lw=2, label=f'Ensemble (AUC = {ensemble_auc:.3f})')\n",
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model Comparison - Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('ensemble_roc_curve.png')\n",
    "plt.close()\n",
    "print(\"Ensemble ROC curve saved to 'ensemble_roc_curve.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 11: Implementing Unanimous Voting Ensemble Approach\n",
      "\n",
      "Unanimous Voting Ensemble Implementation Complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Implementing Unanimous Voting Ensemble Approach\n",
    "\n",
    "print(\"\\nStep 11: Implementing Unanimous Voting Ensemble Approach\")\n",
    "\n",
    "# Function to perform unanimous voting ensemble\n",
    "def unanimous_voting_ensemble(row_probs, col_probs):\n",
    "    \"\"\"\n",
    "    Perform unanimous voting ensemble on predictions from row-wise and column-wise models.\n",
    "    Only make a strong prediction when models agree; use 0.5 (uncertain) when they disagree.\n",
    "    \n",
    "    Args:\n",
    "        row_probs: Probability predictions from row-wise model\n",
    "        col_probs: Probability predictions from column-wise model\n",
    "        \n",
    "    Returns:\n",
    "        Ensemble probabilities and binary predictions\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Convert to numpy arrays if they aren't already\n",
    "    row_probs = np.array(row_probs)\n",
    "    col_probs = np.array(col_probs)\n",
    "    \n",
    "    # Get binary predictions\n",
    "    row_preds = (row_probs >= 0.5).astype(float)\n",
    "    col_preds = (col_probs >= 0.5).astype(float)\n",
    "    \n",
    "    # Find where predictions agree\n",
    "    agreement = (row_preds == col_preds)\n",
    "    \n",
    "    # Initialize ensemble probs at 0.5 (uncertain)\n",
    "    ensemble_probs = np.ones_like(row_probs) * 0.5\n",
    "    \n",
    "    # Where models agree, use the average of their probabilities\n",
    "    ensemble_probs[agreement] = (row_probs[agreement] + col_probs[agreement]) / 2\n",
    "    \n",
    "    # Convert to binary predictions (threshold at 0.5)\n",
    "    ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "    \n",
    "    return ensemble_probs, ensemble_preds\n",
    "\n",
    "# Apply unanimous voting ensemble to our model predictions\n",
    "ensemble_probs, ensemble_preds = unanimous_voting_ensemble(row_preds_prob, col_preds_prob)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nUnanimous Voting Ensemble Implementation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unanimous Voting Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.15      0.23       164\n",
      "         1.0       0.51      0.88      0.64       163\n",
      "\n",
      "    accuracy                           0.51       327\n",
      "   macro avg       0.53      0.51      0.44       327\n",
      "weighted avg       0.53      0.51      0.44       327\n",
      "\n",
      "\n",
      "Unanimous Voting Ensemble Confusion Matrix:\n",
      "[[ 24 140]\n",
      " [ 20 143]]\n",
      "Unanimous Voting Ensemble AUC: 0.5212\n",
      "Unanimous Voting Ensemble Accuracy: 0.5107\n",
      "Unanimous Voting Ensemble Sensitivity: 0.8773\n",
      "Unanimous Voting Ensemble Specificity: 0.1463\n",
      "\n",
      "Models agreement rate: 52.91%\n",
      "ROC curve saved to 'unanimous_voting_ensemble_roc.png'\n",
      "\n",
      "Model Comparison Summary:\n",
      "           Model      AUC  Accuracy  Sensitivity  Specificity                              Description\n",
      "        Row-wise 0.534154  0.525994     0.546012     0.506098             Analyzes each lead over time\n",
      "     Column-wise 0.525438  0.507645     0.748466     0.268293 Analyzes across leads at each time point\n",
      "  Simple Average 0.536174     False     0.644172     0.439024  Average of row and column probabilities\n",
      "Unanimous Voting 0.521192  0.510703     0.877301     0.146341 Strong prediction only when models agree\n",
      "Model comparison saved to 'unanimous_voting_ensemble_comparison.csv'\n",
      "Predictions saved to 'chagas_predictions_with_unanimous_ensemble.csv'\n",
      "Agreement analysis saved to 'unanimous_ensemble_agreement_analysis.png'\n",
      "\n",
      "----------------------------------------------\n",
      "Key Findings for Unanimous Voting Ensemble:\n",
      "1. Models agree on 52.91% of samples\n",
      "2. Unanimous Voting AUC: 0.5212\n",
      "3. When models disagree, the ensemble marks 154 cases as uncertain (50% probability)\n",
      "4. The unanimous voting ensemble provides a cautious approach that flags disagreements\n",
      "5. This approach is suitable for medical diagnosis where flagging uncertain cases can prompt further review\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\nUnanimous Voting Ensemble Classification Report:\")\n",
    "print(classification_report(final_labels, ensemble_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(final_labels, ensemble_preds)\n",
    "print(\"\\nUnanimous Voting Ensemble Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr_ensemble, tpr_ensemble, _ = roc_curve(final_labels, ensemble_probs)\n",
    "ensemble_auc = auc(fpr_ensemble, tpr_ensemble)\n",
    "print(f\"Unanimous Voting Ensemble AUC: {ensemble_auc:.4f}\")\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "ensemble_sensitivity = recall_score(final_labels, ensemble_preds, pos_label=1)\n",
    "ensemble_specificity = recall_score(final_labels, ensemble_preds, pos_label=0)\n",
    "ensemble_accuracy = (ensemble_preds == final_labels).mean()\n",
    "print(f\"Unanimous Voting Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
    "print(f\"Unanimous Voting Ensemble Sensitivity: {ensemble_sensitivity:.4f}\")\n",
    "print(f\"Unanimous Voting Ensemble Specificity: {ensemble_specificity:.4f}\")\n",
    "\n",
    "# Calculate the percentage of samples where models agree\n",
    "agreement_rate = np.mean((row_preds == col_preds).astype(float)) * 100\n",
    "print(f\"\\nModels agreement rate: {agreement_rate:.2f}%\")\n",
    "\n",
    "# Plot ROC curves comparing all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Row-wise model ROC\n",
    "fpr_row, tpr_row, _ = roc_curve(row_labels, row_preds_prob)\n",
    "plt.plot(fpr_row, tpr_row, color='blue', lw=2, label=f'Row-wise (AUC = {row_auc:.3f})')\n",
    "\n",
    "# Column-wise model ROC\n",
    "fpr_col, tpr_col, _ = roc_curve(col_labels, col_preds_prob)\n",
    "plt.plot(fpr_col, tpr_col, color='red', lw=2, label=f'Column-wise (AUC = {col_auc:.3f})')\n",
    "\n",
    "# Simple Average Ensemble (post-hoc)\n",
    "simple_avg_probs = (np.array(row_preds_prob) + np.array(col_preds_prob)) / 2\n",
    "fpr_simple, tpr_simple, _ = roc_curve(final_labels, simple_avg_probs)\n",
    "simple_auc = auc(fpr_simple, tpr_simple)\n",
    "plt.plot(fpr_simple, tpr_simple, color='green', lw=2, linestyle='--', \n",
    "         label=f'Simple Average (AUC = {simple_auc:.3f})')\n",
    "\n",
    "# Unanimous Voting Ensemble ROC\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, color='purple', lw=2, \n",
    "         label=f'Unanimous Voting (AUC = {ensemble_auc:.3f})')\n",
    "\n",
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model Comparison - Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('unanimous_voting_ensemble_roc.png')\n",
    "plt.close()\n",
    "print(\"ROC curve saved to 'unanimous_voting_ensemble_roc.png'\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Row-wise', 'Column-wise', 'Simple Average', 'Unanimous Voting'],\n",
    "    'AUC': [row_auc, col_auc, simple_auc, ensemble_auc],\n",
    "    'Accuracy': [\n",
    "        (row_preds == final_labels).mean(), \n",
    "        (col_preds == final_labels).mean(), \n",
    "        (simple_avg_probs >= 0.5).astype(int).mean() == final_labels.mean(),\n",
    "        ensemble_accuracy\n",
    "    ],\n",
    "    'Sensitivity': [\n",
    "        recall_score(final_labels, row_preds, pos_label=1),\n",
    "        recall_score(final_labels, col_preds, pos_label=1),\n",
    "        recall_score(final_labels, (simple_avg_probs >= 0.5).astype(int), pos_label=1),\n",
    "        ensemble_sensitivity\n",
    "    ],\n",
    "    'Specificity': [\n",
    "        recall_score(final_labels, row_preds, pos_label=0),\n",
    "        recall_score(final_labels, col_preds, pos_label=0),\n",
    "        recall_score(final_labels, (simple_avg_probs >= 0.5).astype(int), pos_label=0),\n",
    "        ensemble_specificity\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Analyzes each lead over time', \n",
    "        'Analyzes across leads at each time point', \n",
    "        'Average of row and column probabilities',\n",
    "        'Strong prediction only when models agree'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "print(model_comparison.to_string(index=False))\n",
    "\n",
    "# Save comparison to CSV\n",
    "model_comparison.to_csv('unanimous_voting_ensemble_comparison.csv', index=False)\n",
    "print(\"Model comparison saved to 'unanimous_voting_ensemble_comparison.csv'\")\n",
    "\n",
    "# Create DataFrame with predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'exam_id': original_test_ids,\n",
    "    'true_chagas': final_labels,\n",
    "    'row_predicted_prob': row_preds_prob,\n",
    "    'row_predicted_chagas': row_preds,\n",
    "    'col_predicted_prob': col_preds_prob,\n",
    "    'col_predicted_chagas': col_preds,\n",
    "    'simple_avg_prob': simple_avg_probs,\n",
    "    'simple_avg_chagas': (simple_avg_probs >= 0.5).astype(int),\n",
    "    'unanimous_ensemble_prob': ensemble_probs,\n",
    "    'unanimous_ensemble_chagas': ensemble_preds,\n",
    "    'models_agree': (row_preds == col_preds)\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('chagas_predictions_with_unanimous_ensemble.csv', index=False)\n",
    "print(\"Predictions saved to 'chagas_predictions_with_unanimous_ensemble.csv'\")\n",
    "\n",
    "# Create visualization showing the agreement between models\n",
    "agree_correct = np.sum((row_preds == col_preds) & (ensemble_preds == final_labels))\n",
    "agree_incorrect = np.sum((row_preds == col_preds) & (ensemble_preds != final_labels))\n",
    "disagree_correct = np.sum((row_preds != col_preds) & (ensemble_probs >= 0.5) & (ensemble_preds == final_labels))\n",
    "disagree_incorrect = np.sum((row_preds != col_preds) & (ensemble_probs >= 0.5) & (ensemble_preds != final_labels))\n",
    "disagree_uncertain = np.sum((row_preds != col_preds) & (ensemble_probs == 0.5))\n",
    "\n",
    "# Create pie chart showing agreement and correctness\n",
    "labels = ['Models agree & correct', 'Models agree & incorrect', \n",
    "          'Models disagree & correct', 'Models disagree & incorrect',\n",
    "          'Models disagree (uncertain)']\n",
    "sizes = [agree_correct, agree_incorrect, disagree_correct, disagree_incorrect, disagree_uncertain]\n",
    "colors = ['#66b266', '#ff6666', '#66b2ff', '#ffb266', '#c2c2d6']\n",
    "explode = (0.1, 0, 0, 0, 0.1)  # explode the 1st and last slice\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.title('Model Agreement and Prediction Correctness')\n",
    "plt.savefig('unanimous_ensemble_agreement_analysis.png')\n",
    "plt.close()\n",
    "print(\"Agreement analysis saved to 'unanimous_ensemble_agreement_analysis.png'\")\n",
    "\n",
    "# Summarize findings\n",
    "print(\"\\n----------------------------------------------\")\n",
    "print(\"Key Findings for Unanimous Voting Ensemble:\")\n",
    "print(f\"1. Models agree on {agreement_rate:.2f}% of samples\")\n",
    "print(f\"2. Unanimous Voting AUC: {ensemble_auc:.4f}\")\n",
    "print(f\"3. When models disagree, the ensemble marks {disagree_uncertain} cases as uncertain (50% probability)\")\n",
    "print(\"4. The unanimous voting ensemble provides a cautious approach that flags disagreements\")\n",
    "print(\"5. This approach is suitable for medical diagnosis where flagging uncertain cases can prompt further review\")\n",
    "print(\"----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
