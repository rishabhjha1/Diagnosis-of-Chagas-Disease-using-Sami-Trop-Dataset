{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, recall_score\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading CSV data\n",
      "Exams data: 1631 rows\n",
      "Labels data: 815 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load CSV data\n",
    "print(\"Step 1: Loading CSV data\")\n",
    "exams_df = pd.read_csv('exams.csv')\n",
    "labels_df = pd.read_csv('samitrop_chagas_labels.csv')\n",
    "\n",
    "print(f\"Exams data: {len(exams_df)} rows\")\n",
    "print(f\"Labels data: {len(labels_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exams data sample:\n",
      "   exam_id  age  is_male  normal_ecg  death     timey  nn_predicted_age\n",
      "0   294669   67     True       False  False  2.116020         51.093110\n",
      "1   291318   65     True       False  False  3.077345         76.923935\n",
      "2   247007   67    False       False  False  2.378450         61.212074\n",
      "\n",
      "Labels data sample:\n",
      "   exam_id  chagas\n",
      "0   247007    True\n",
      "1   181629    True\n",
      "2   406936    True\n"
     ]
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"\\nExams data sample:\")\n",
    "print(exams_df.head(3))\n",
    "print(\"\\nLabels data sample:\")\n",
    "print(labels_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total records: 1631\n"
     ]
    }
   ],
   "source": [
    "# Set all exams as negative by default\n",
    "exams_df['chagas'] = 0\n",
    "\n",
    "# Update the chagas labels for the 815 IDs in labels_df to be positive\n",
    "exams_df.loc[exams_df['exam_id'].isin(labels_df['exam_id']), 'chagas'] = 1\n",
    "\n",
    "\n",
    "merged_df = exams_df\n",
    "print(f\"\\nTotal records: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chagas positive: 815 (49.97%)\n",
      "Chagas negative: 816 (50.03%)\n"
     ]
    }
   ],
   "source": [
    "# Check class balance\n",
    "chagas_count = merged_df['chagas'].sum()\n",
    "print(f\"Chagas positive: {chagas_count} ({chagas_count/len(merged_df)*100:.2f}%)\")\n",
    "print(f\"Chagas negative: {len(merged_df) - chagas_count} ({(1-chagas_count/len(merged_df))*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Loading ECG data from HDF5 file\n",
      "HDF5 file structure:\n",
      "Key: tracings\n",
      "  Type: Dataset\n",
      "  Shape: (1631, 4096, 12)\n",
      "\n",
      "Accessing 'tracings' dataset\n",
      "Tracings shape: (1631, 4096, 12)\n",
      "No explicit exam_id mapping found. Assuming sequential ordering.\n",
      "\n",
      "Loading ECG data...\n",
      "  Progress: 0/1631 ECGs loaded\n",
      "  First ECG shape: (4096, 12)\n",
      "  Progress: 100/1631 ECGs loaded\n",
      "  Progress: 200/1631 ECGs loaded\n",
      "  Progress: 300/1631 ECGs loaded\n",
      "  Progress: 400/1631 ECGs loaded\n",
      "  Progress: 500/1631 ECGs loaded\n",
      "  Progress: 600/1631 ECGs loaded\n",
      "  Progress: 700/1631 ECGs loaded\n",
      "  Progress: 800/1631 ECGs loaded\n",
      "  Progress: 900/1631 ECGs loaded\n",
      "  Progress: 1000/1631 ECGs loaded\n",
      "  Progress: 1100/1631 ECGs loaded\n",
      "  Progress: 1200/1631 ECGs loaded\n",
      "  Progress: 1300/1631 ECGs loaded\n",
      "  Progress: 1400/1631 ECGs loaded\n",
      "  Progress: 1500/1631 ECGs loaded\n",
      "  Progress: 1600/1631 ECGs loaded\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load ECG data from HDF5 file\n",
    "print(\"\\nStep 2: Loading ECG data from HDF5 file\")\n",
    "\n",
    "if not os.path.exists('exams.hdf5'):\n",
    "    raise FileNotFoundError(\"The file 'exams.hdf5' was not found in the current directory.\")\n",
    "\n",
    "# Open HDF5 file\n",
    "with h5py.File('exams.hdf5', 'r') as hdf:\n",
    "    # Print the structure of the HDF5 file\n",
    "    print(\"HDF5 file structure:\")\n",
    "    for key in hdf.keys():\n",
    "        print(f\"Key: {key}\")\n",
    "        if isinstance(hdf[key], h5py.Group):\n",
    "            print(f\"  Type: Group\")\n",
    "            for subkey in hdf[key].keys():\n",
    "                print(f\"  Subkey: {subkey}\")\n",
    "        else:\n",
    "            print(f\"  Type: Dataset\")\n",
    "            print(f\"  Shape: {hdf[key].shape}\")\n",
    "    \n",
    "    # Your HDF5 has a 'tracings' key\n",
    "    if 'tracings' in hdf:\n",
    "        print(\"\\nAccessing 'tracings' dataset\")\n",
    "        tracings = hdf['tracings']\n",
    "        print(f\"Tracings shape: {tracings.shape}\")\n",
    "        \n",
    "        # Check if there's an 'exam_id' dataset that maps indices to exam_ids\n",
    "        if 'exam_id' in hdf:\n",
    "            # If there's a mapping between indices and exam_ids\n",
    "            exam_id_mapping = hdf['exam_id'][:]\n",
    "            print(f\"Found exam_id mapping with {len(exam_id_mapping)} entries\")\n",
    "        else:\n",
    "            # If there's no explicit mapping, we'll need to determine how tracings map to exam_ids\n",
    "            print(\"No explicit exam_id mapping found. Assuming sequential ordering.\")\n",
    "            # Here we're assuming that the order of tracings corresponds to the order of exam_ids in the CSV\n",
    "            exam_id_mapping = merged_df['exam_id'].values\n",
    "            if len(exam_id_mapping) != tracings.shape[0]:\n",
    "                print(f\"Warning: Number of tracings ({tracings.shape[0]}) doesn't match number of exam_ids ({len(exam_id_mapping)})\")\n",
    "                # Use the minimum number to avoid index errors\n",
    "                min_length = min(len(exam_id_mapping), tracings.shape[0])\n",
    "                exam_id_mapping = exam_id_mapping[:min_length]\n",
    "                print(f\"Using first {min_length} exam_ids for mapping\")\n",
    "        \n",
    "        # Initialize lists to store ECG data and labels\n",
    "        ecg_data = []\n",
    "        labels = []\n",
    "        original_ids = []\n",
    "        \n",
    "        # Load ECG data for each exam\n",
    "        print(\"\\nLoading ECG data...\")\n",
    "        for i in range(len(exam_id_mapping)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"  Progress: {i}/{len(exam_id_mapping)} ECGs loaded\")\n",
    "            \n",
    "            # Get the exam_id for this tracing\n",
    "            exam_id = exam_id_mapping[i]\n",
    "            \n",
    "            # Get the label from our merged dataframe\n",
    "            label_row = merged_df.loc[merged_df['exam_id'] == exam_id]\n",
    "            if len(label_row) == 0:\n",
    "                print(f\"  Warning: No label found for ID {exam_id}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            label = label_row['chagas'].values[0]\n",
    "            \n",
    "            try:\n",
    "                # Get the ECG data\n",
    "                ecg = tracings[i]\n",
    "                \n",
    "                # Check and fix shape if needed\n",
    "                if len(ecg.shape) == 1:\n",
    "                    # If it's one-dimensional, reshape it\n",
    "                    print(f\"  Single-dimension ECG found with shape {ecg.shape}. Reshaping...\")\n",
    "                    # Assume it's 12 leads concatenated\n",
    "                    n_samples = ecg.shape[0] // 12\n",
    "                    ecg = ecg.reshape(n_samples, 12)\n",
    "                \n",
    "                # Print shape info for the first ECG\n",
    "                if i == 0:\n",
    "                    print(f\"  First ECG shape: {ecg.shape}\")\n",
    "                    # If shape is (12, time_points) instead of (time_points, 12), transpose it\n",
    "                    if ecg.shape[1] != 12 and ecg.shape[0] == 12:\n",
    "                        print(\"  Transposing ECG data to get (time_points, leads) format\")\n",
    "                        ecg = ecg.T\n",
    "                        print(f\"  Transposed shape: {ecg.shape}\")\n",
    "                \n",
    "                # Add to lists\n",
    "                ecg_data.append(ecg)\n",
    "                labels.append(label)\n",
    "                original_ids.append(exam_id)\n",
    "            except Exception as e:\n",
    "                print(f\"  Error loading ECG for ID {exam_id}: {e}\")\n",
    "                continue\n",
    "    else:\n",
    "        raise ValueError(\"Expected 'tracings' dataset not found in HDF5 file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1631 ECGs\n",
      "Final ECG data shape: (1631, 4096, 12)\n",
      "Labels shape: (1631,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if we loaded any data\n",
    "if len(ecg_data) == 0:\n",
    "    raise ValueError(\"No ECG data was successfully loaded. Cannot proceed.\")\n",
    "\n",
    "print(f\"Successfully loaded {len(ecg_data)} ECGs\")\n",
    "\n",
    "# Check if ECGs have consistent shapes\n",
    "shapes = [ecg.shape for ecg in ecg_data]\n",
    "unique_shapes = set(shapes)\n",
    "if len(unique_shapes) > 1:\n",
    "    print(f\"Warning: Inconsistent ECG shapes detected. Found {len(unique_shapes)} different shapes.\")\n",
    "    \n",
    "    # Find the most common shape\n",
    "    most_common_shape = max(unique_shapes, key=shapes.count)\n",
    "    print(f\"Using most common shape: {most_common_shape}\")\n",
    "    \n",
    "    # Filter to keep only ECGs with the most common shape\n",
    "    filtered_data = []\n",
    "    filtered_labels = []\n",
    "    filtered_ids = []\n",
    "    for i in range(len(ecg_data)):\n",
    "        if ecg_data[i].shape == most_common_shape:\n",
    "            filtered_data.append(ecg_data[i])\n",
    "            filtered_labels.append(labels[i])\n",
    "            filtered_ids.append(original_ids[i])\n",
    "    \n",
    "    ecg_data = filtered_data\n",
    "    labels = filtered_labels\n",
    "    original_ids = filtered_ids\n",
    "    print(f\"After filtering: {len(ecg_data)} ECGs with consistent shape\")\n",
    "\n",
    "# Create numpy arrays for model training\n",
    "# Ensure all ECGs have the same length\n",
    "if len(ecg_data) > 0:\n",
    "    time_points = max(ecg.shape[0] for ecg in ecg_data)\n",
    "    n_leads = ecg_data[0].shape[1]  # Typically 12 for standard ECG\n",
    "    \n",
    "    X = np.zeros((len(ecg_data), time_points, n_leads))\n",
    "    for i, ecg in enumerate(ecg_data):\n",
    "        # Pad or truncate to the same length\n",
    "        if ecg.shape[0] < time_points:\n",
    "            # Pad with zeros\n",
    "            X[i, :ecg.shape[0], :] = ecg\n",
    "        else:\n",
    "            # Truncate\n",
    "            X[i, :, :] = ecg[:time_points, :]\n",
    "            \n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"Final ECG data shape: {X.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Preprocessing ECG data\n",
      "Training set size: (1304, 4096, 12)\n",
      "Testing set size: (327, 4096, 12)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preprocess ECG data\n",
    "print(\"\\nStep 3: Preprocessing ECG data\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_indices = np.arange(len(X))\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    X, y, X_indices, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")\n",
    "\n",
    "# Normalize each ECG to have zero mean and unit variance\n",
    "for i in range(X_train.shape[0]):\n",
    "    for lead in range(X_train.shape[2]):\n",
    "        # Avoid division by zero\n",
    "        std = np.std(X_train[i, :, lead])\n",
    "        if std == 0:\n",
    "            X_train[i, :, lead] = 0\n",
    "        else:\n",
    "            X_train[i, :, lead] = (X_train[i, :, lead] - np.mean(X_train[i, :, lead])) / std\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    for lead in range(X_test.shape[2]):\n",
    "        # Avoid division by zero\n",
    "        std = np.std(X_test[i, :, lead])\n",
    "        if std == 0:\n",
    "            X_test[i, :, lead] = 0\n",
    "        else:\n",
    "            X_test[i, :, lead] = (X_test[i, :, lead] - np.mean(X_test[i, :, lead])) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Visualizing sample ECGs\n",
      "Sample ECGs saved to 'sample_ecgs.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Visualize sample ECGs\n",
    "print(\"\\nStep 4: Visualizing sample ECGs\")\n",
    "\n",
    "# Get indices of Chagas positive and negative samples\n",
    "pos_indices = np.where(y == 1)[0]\n",
    "neg_indices = np.where(y == 0)[0]\n",
    "\n",
    "# Check if we have samples of both classes\n",
    "if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "    # Number of samples to visualize\n",
    "    n_samples = 2\n",
    "    \n",
    "    # Plot Chagas positive and negative samples\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot Chagas positive samples\n",
    "    for i in range(min(n_samples, len(pos_indices))):\n",
    "        idx = pos_indices[i]\n",
    "        plt.subplot(2, n_samples, i+1)\n",
    "        \n",
    "        # Plot all leads\n",
    "        for lead in range(X.shape[2]):\n",
    "            plt.plot(X[idx, :, lead], alpha=0.7, linewidth=0.5)\n",
    "        \n",
    "        plt.title(f\"Chagas Positive (ID: {original_ids[idx]})\")\n",
    "        plt.ylim(-5, 5)\n",
    "    \n",
    "    # Plot Chagas negative samples\n",
    "    for i in range(min(n_samples, len(neg_indices))):\n",
    "        idx = neg_indices[i]\n",
    "        plt.subplot(2, n_samples, i+n_samples+1)\n",
    "        \n",
    "        # Plot all leads\n",
    "        for lead in range(X.shape[2]):\n",
    "            plt.plot(X[idx, :, lead], alpha=0.7, linewidth=0.5)\n",
    "        \n",
    "        plt.title(f\"Chagas Negative (ID: {original_ids[idx]})\")\n",
    "        plt.ylim(-5, 5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_ecgs.png')\n",
    "    plt.close()\n",
    "    print(\"Sample ECGs saved to 'sample_ecgs.png'\")\n",
    "else:\n",
    "    print(\"Cannot visualize: missing examples from one or both classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Creating PyTorch Dataset and DataLoader\n",
      "Created train_loader with 82 batches of size 16\n",
      "Created test_loader with 21 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "# Step 5: PyTorch Dataset and DataLoader\n",
    "print(\"\\nStep 5: Creating PyTorch Dataset and DataLoader\")\n",
    "\n",
    "# Define a custom Dataset class\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, ecg_data, labels):\n",
    "        self.ecg_data = torch.tensor(ecg_data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ecg_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ecg = self.ecg_data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return ecg, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset = ECGDataset(X_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Created train_loader with {len(train_loader)} batches of size {batch_size}\")\n",
    "print(f\"Created test_loader with {len(test_loader)} batches of size {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Building PyTorch CNN model\n",
      "Using device: cpu\n",
      "ECGModel(\n",
      "  (conv1): Conv1d(12, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=131072, out_features=64, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 8433729\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Define PyTorch model\n",
    "print(\"\\nStep 6: Building PyTorch CNN model\")\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the CNN model\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=12):\n",
    "        super(ECGModel, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the size of flattened features after convolutions and pooling\n",
    "        # For a time series of length L, after two pooling layers of kernel_size=2, we have L/4\n",
    "        self.flattened_size = (time_points // 4) * 128\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # PyTorch Conv1d expects input shape (batch_size, channels, seq_length)\n",
    "        # Our data is (batch_size, seq_length, channels), so we need to permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu3(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = ECGModel(input_channels=n_leads)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Training model\n",
      "Epoch [1/20], Batch [10/82], Loss: 0.7007\n",
      "Epoch [1/20], Batch [20/82], Loss: 0.7069\n",
      "Epoch [1/20], Batch [30/82], Loss: 0.6903\n",
      "Epoch [1/20], Batch [40/82], Loss: 0.6891\n",
      "Epoch [1/20], Batch [50/82], Loss: 0.6955\n",
      "Epoch [1/20], Batch [60/82], Loss: 0.6906\n",
      "Epoch [1/20], Batch [70/82], Loss: 0.6844\n",
      "Epoch [1/20], Batch [80/82], Loss: 0.6863\n",
      "Epoch [1/20] - 39.84s - Loss: 0.8762, Acc: 0.4923, Val Loss: 0.6935, Val Acc: 0.4924\n",
      "Epoch [2/20], Batch [10/82], Loss: 0.6904\n",
      "Epoch [2/20], Batch [20/82], Loss: 0.6945\n",
      "Epoch [2/20], Batch [30/82], Loss: 0.6740\n",
      "Epoch [2/20], Batch [40/82], Loss: 0.6965\n",
      "Epoch [2/20], Batch [50/82], Loss: 0.6907\n",
      "Epoch [2/20], Batch [60/82], Loss: 0.6967\n",
      "Epoch [2/20], Batch [70/82], Loss: 0.6776\n",
      "Epoch [2/20], Batch [80/82], Loss: 0.6864\n",
      "Epoch [2/20] - 39.12s - Loss: 0.6922, Acc: 0.5130, Val Loss: 0.6912, Val Acc: 0.5229\n",
      "Epoch [3/20], Batch [10/82], Loss: 0.6654\n",
      "Epoch [3/20], Batch [20/82], Loss: 0.6807\n",
      "Epoch [3/20], Batch [30/82], Loss: 0.6975\n",
      "Epoch [3/20], Batch [40/82], Loss: 0.6796\n",
      "Epoch [3/20], Batch [50/82], Loss: 0.6530\n",
      "Epoch [3/20], Batch [60/82], Loss: 0.7166\n",
      "Epoch [3/20], Batch [70/82], Loss: 0.6448\n",
      "Epoch [3/20], Batch [80/82], Loss: 0.6583\n",
      "Epoch [3/20] - 36.80s - Loss: 0.6830, Acc: 0.5544, Val Loss: 0.6911, Val Acc: 0.5229\n",
      "Epoch [4/20], Batch [10/82], Loss: 0.6219\n",
      "Epoch [4/20], Batch [20/82], Loss: 0.6347\n",
      "Epoch [4/20], Batch [30/82], Loss: 0.7412\n",
      "Epoch [4/20], Batch [40/82], Loss: 0.4884\n",
      "Epoch [4/20], Batch [50/82], Loss: 0.7048\n",
      "Epoch [4/20], Batch [60/82], Loss: 0.6154\n",
      "Epoch [4/20], Batch [70/82], Loss: 0.6212\n",
      "Epoch [4/20], Batch [80/82], Loss: 0.5918\n",
      "Epoch [4/20] - 41.30s - Loss: 0.6454, Acc: 0.6273, Val Loss: 0.7229, Val Acc: 0.5138\n",
      "Epoch [5/20], Batch [10/82], Loss: 0.4896\n",
      "Epoch [5/20], Batch [20/82], Loss: 0.5837\n",
      "Epoch [5/20], Batch [30/82], Loss: 0.4778\n",
      "Epoch [5/20], Batch [40/82], Loss: 0.5386\n",
      "Epoch [5/20], Batch [50/82], Loss: 0.6769\n",
      "Epoch [5/20], Batch [60/82], Loss: 0.4246\n",
      "Epoch [5/20], Batch [70/82], Loss: 0.7919\n",
      "Epoch [5/20], Batch [80/82], Loss: 0.4699\n",
      "Epoch [5/20] - 47.80s - Loss: 0.5850, Acc: 0.6610, Val Loss: 0.7186, Val Acc: 0.5291\n",
      "Epoch [6/20], Batch [10/82], Loss: 0.4738\n",
      "Epoch [6/20], Batch [20/82], Loss: 0.4333\n",
      "Epoch [6/20], Batch [30/82], Loss: 0.6541\n",
      "Epoch [6/20], Batch [40/82], Loss: 0.5003\n",
      "Epoch [6/20], Batch [50/82], Loss: 0.4503\n",
      "Epoch [6/20], Batch [60/82], Loss: 0.4196\n",
      "Epoch [6/20], Batch [70/82], Loss: 0.5419\n",
      "Epoch [6/20], Batch [80/82], Loss: 0.7193\n",
      "Epoch [6/20] - 47.86s - Loss: 0.4938, Acc: 0.7446, Val Loss: 0.8548, Val Acc: 0.5015\n",
      "Epoch [7/20], Batch [10/82], Loss: 0.4203\n",
      "Epoch [7/20], Batch [20/82], Loss: 0.5587\n",
      "Epoch [7/20], Batch [30/82], Loss: 0.4015\n",
      "Epoch [7/20], Batch [40/82], Loss: 0.3135\n",
      "Epoch [7/20], Batch [50/82], Loss: 0.4444\n",
      "Epoch [7/20], Batch [60/82], Loss: 0.3334\n",
      "Epoch [7/20], Batch [70/82], Loss: 0.4347\n",
      "Epoch [7/20], Batch [80/82], Loss: 0.3455\n",
      "Epoch [7/20] - 33.55s - Loss: 0.4153, Acc: 0.7807, Val Loss: 0.8810, Val Acc: 0.5046\n",
      "Epoch [8/20], Batch [10/82], Loss: 0.4983\n",
      "Epoch [8/20], Batch [20/82], Loss: 0.4181\n",
      "Epoch [8/20], Batch [30/82], Loss: 0.2187\n",
      "Epoch [8/20], Batch [40/82], Loss: 0.2420\n",
      "Epoch [8/20], Batch [50/82], Loss: 0.3717\n",
      "Epoch [8/20], Batch [60/82], Loss: 0.3228\n",
      "Epoch [8/20], Batch [70/82], Loss: 0.5236\n",
      "Epoch [8/20], Batch [80/82], Loss: 0.3620\n",
      "Epoch [8/20] - 31.67s - Loss: 0.3322, Acc: 0.8298, Val Loss: 1.0063, Val Acc: 0.5505\n",
      "Early stopping triggered after epoch 8\n",
      "Loaded best model with validation loss: 0.6911\n",
      "Training history saved to 'training_history.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the model\n",
    "print(\"\\nStep 8: Training model\")\n",
    "\n",
    "# Tracking variables\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Print progress\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate validation statistics\n",
    "    val_epoch_loss = val_loss / len(test_dataset)\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accs.append(val_epoch_acc)\n",
    "    \n",
    "    # Print epoch results\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - {epoch_time:.2f}s - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Load the best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"Loaded best model with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(val_accs, label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()\n",
    "print(\"Training history saved to 'training_history.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9: Evaluating model\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.56      0.56       164\n",
      "         1.0       0.55      0.54      0.54       163\n",
      "\n",
      "    accuracy                           0.55       327\n",
      "   macro avg       0.55      0.55      0.55       327\n",
      "weighted avg       0.55      0.55      0.55       327\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[92 72]\n",
      " [75 88]]\n",
      "ROC curve saved to 'roc_curve.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Evaluate model\n",
    "print(\"\\nStep 9: Evaluating model\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize arrays to store predictions and true labels\n",
    "all_preds = []\n",
    "all_preds_prob = []\n",
    "all_labels = []\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert to CPU and numpy for evaluation\n",
    "        preds_prob = outputs.cpu().numpy()\n",
    "        preds = (outputs > 0.5).float().cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        # Append batch predictions to lists\n",
    "        all_preds.extend(preds)\n",
    "        all_preds_prob.extend(preds_prob)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_preds_prob = np.array(all_preds_prob).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_preds_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.close()\n",
    "print(\"ROC curve saved to 'roc_curve.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10: Saving results\n",
      "Model saved to 'chagas_detection_model.pth'\n",
      "Predictions saved to 'chagas_predictions.csv'\n",
      "\n",
      "Script completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Save model and results\n",
    "print(\"\\nStep 10: Saving results\")\n",
    "\n",
    "# Save PyTorch model\n",
    "torch.save(model.state_dict(), 'chagas_detection_model.pth')\n",
    "print(\"Model saved to 'chagas_detection_model.pth'\")\n",
    "\n",
    "# Map back to original exam IDs\n",
    "original_test_ids = [original_ids[i] for i in test_indices]\n",
    "\n",
    "# Create DataFrame with predictions for future use\n",
    "predictions_df = pd.DataFrame({\n",
    "    'exam_id': original_test_ids,\n",
    "    'true_chagas': all_labels,\n",
    "    'predicted_prob': all_preds_prob,\n",
    "    'predicted_chagas': all_preds\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('chagas_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'chagas_predictions.csv'\")\n",
    "\n",
    "print(\"\\nScript completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Row-wise CNN model (analyzes each lead over time)\n",
    "class RowWiseECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=12):\n",
    "        super(RowWiseECGModel, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the size of flattened features after convolutions and pooling\n",
    "        # For a time series of length L, after two pooling layers of kernel_size=2, we have L/4\n",
    "        self.flattened_size = (time_points // 4) * 128\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # PyTorch Conv1d expects input shape (batch_size, channels, seq_length)\n",
    "        # Our data is (batch_size, seq_length, channels), so we need to permute\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu3(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Column-wise CNN model (analyzes across leads at each time point)\n",
    "class ColumnWiseECGModel(nn.Module):\n",
    "    def __init__(self, input_channels=time_points):\n",
    "        super(ColumnWiseECGModel, self).__init__()\n",
    "        \n",
    "        # First convolutional block - now operating across leads at each time point\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the size of flattened features after convolutions and pooling\n",
    "        # For leads dimension, which is typically 12, after pooling it becomes 12/4 = 3 (or less if leads < 12)\n",
    "        self.flattened_size = (n_leads // 4 if n_leads >= 4 else 1) * 128\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # No need to permute - we'll view the data differently\n",
    "        # We want (batch_size, time_points, leads) -> (batch_size, time_points, leads)\n",
    "        # This already has time_points as \"channels\" and leads as the \"sequence\"\n",
    "        \n",
    "        # Reshape to make time_points the channels dimension\n",
    "        x = x.permute(0, 1, 2)  # Now it's (batch_size, time_points, leads)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout1(self.relu3(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise Model (analyzing each lead over time):\n",
      "RowWiseECGModel(\n",
      "  (conv1): Conv1d(12, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=131072, out_features=64, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 8433729\n",
      "\n",
      "Column-wise Model (analyzing across leads at each time point):\n",
      "ColumnWiseECGModel(\n",
      "  (conv1): Conv1d(4096, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=384, out_features=64, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 835905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize both models\n",
    "row_model = RowWiseECGModel(input_channels=n_leads)\n",
    "row_model = row_model.to(device)\n",
    "\n",
    "col_model = ColumnWiseECGModel(input_channels=time_points)\n",
    "col_model = col_model.to(device)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Row-wise Model (analyzing each lead over time):\")\n",
    "print(row_model)\n",
    "row_params = sum(p.numel() for p in row_model.parameters())\n",
    "print(f\"Total parameters: {row_params}\")\n",
    "\n",
    "print(\"\\nColumn-wise Model (analyzing across leads at each time point):\")\n",
    "print(col_model)\n",
    "col_params = sum(p.numel() for p in col_model.parameters())\n",
    "print(f\"Total parameters: {col_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Row-wise Model for training\n"
     ]
    }
   ],
   "source": [
    "# Choose which model to use for training\n",
    "model_type = \"row\"  # Options: \"row\" or \"col\"\n",
    "\n",
    "if model_type == \"row\":\n",
    "    model = row_model\n",
    "    print(\"\\nUsing Row-wise Model for training\")\n",
    "else:\n",
    "    model = col_model\n",
    "    print(\"\\nUsing Column-wise Model for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Training both models\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train both models\n",
    "print(\"\\nStep 8: Training both models\")\n",
    "\n",
    "def train_model(model_name, model, train_loader, test_loader, device, criterion, learning_rate=0.001, num_epochs=20, patience=5):\n",
    "    print(f\"\\n----- Training {model_name} Model -----\")\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Tracking variables\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Print progress\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate epoch statistics\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate validation statistics\n",
    "        val_epoch_loss = val_loss / len(test_dataset)\n",
    "        val_epoch_acc = val_correct / val_total\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accs.append(val_epoch_acc)\n",
    "        \n",
    "        # Print epoch results\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - {epoch_time:.2f}s - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Loaded best model with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(f'{model_name} Model - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.title(f'{model_name} Model - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name.lower()}_training_history.png')\n",
    "    plt.close()\n",
    "    print(f\"{model_name} Model training history saved to '{model_name.lower()}_training_history.png'\")\n",
    "    \n",
    "    return model, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Training Row-wise Model -----\n",
      "Epoch [1/20], Batch [10/82], Loss: 0.6815\n",
      "Epoch [1/20], Batch [20/82], Loss: 0.6917\n",
      "Epoch [1/20], Batch [30/82], Loss: 0.6690\n",
      "Epoch [1/20], Batch [40/82], Loss: 0.7064\n",
      "Epoch [1/20], Batch [50/82], Loss: 0.6839\n",
      "Epoch [1/20], Batch [60/82], Loss: 0.6850\n",
      "Epoch [1/20], Batch [70/82], Loss: 0.6941\n",
      "Epoch [1/20], Batch [80/82], Loss: 0.7069\n",
      "Epoch [1/20] - 26.30s - Loss: 0.7961, Acc: 0.4885, Val Loss: 0.6935, Val Acc: 0.5015\n",
      "Epoch [2/20], Batch [10/82], Loss: 0.6959\n",
      "Epoch [2/20], Batch [20/82], Loss: 0.6922\n",
      "Epoch [2/20], Batch [30/82], Loss: 0.6828\n",
      "Epoch [2/20], Batch [40/82], Loss: 0.6890\n",
      "Epoch [2/20], Batch [50/82], Loss: 0.6957\n",
      "Epoch [2/20], Batch [60/82], Loss: 0.6983\n",
      "Epoch [2/20], Batch [70/82], Loss: 0.6912\n",
      "Epoch [2/20], Batch [80/82], Loss: 0.6965\n",
      "Epoch [2/20] - 26.76s - Loss: 0.6929, Acc: 0.5038, Val Loss: 0.6925, Val Acc: 0.5199\n",
      "Epoch [3/20], Batch [10/82], Loss: 0.7064\n",
      "Epoch [3/20], Batch [20/82], Loss: 0.6000\n",
      "Epoch [3/20], Batch [30/82], Loss: 0.6851\n",
      "Epoch [3/20], Batch [40/82], Loss: 0.6831\n",
      "Epoch [3/20], Batch [50/82], Loss: 0.6082\n",
      "Epoch [3/20], Batch [60/82], Loss: 0.6151\n",
      "Epoch [3/20], Batch [70/82], Loss: 0.7001\n",
      "Epoch [3/20], Batch [80/82], Loss: 0.6211\n",
      "Epoch [3/20] - 36.35s - Loss: 0.6718, Acc: 0.5759, Val Loss: 0.6987, Val Acc: 0.5229\n",
      "Epoch [4/20], Batch [10/82], Loss: 0.6259\n",
      "Epoch [4/20], Batch [20/82], Loss: 0.6093\n",
      "Epoch [4/20], Batch [30/82], Loss: 0.5632\n",
      "Epoch [4/20], Batch [40/82], Loss: 0.5700\n",
      "Epoch [4/20], Batch [50/82], Loss: 0.4226\n",
      "Epoch [4/20], Batch [60/82], Loss: 0.6806\n",
      "Epoch [4/20], Batch [70/82], Loss: 0.5596\n",
      "Epoch [4/20], Batch [80/82], Loss: 0.5603\n",
      "Epoch [4/20] - 57.19s - Loss: 0.6013, Acc: 0.6618, Val Loss: 0.7433, Val Acc: 0.5229\n",
      "Epoch [5/20], Batch [10/82], Loss: 0.5006\n",
      "Epoch [5/20], Batch [20/82], Loss: 0.4056\n",
      "Epoch [5/20], Batch [30/82], Loss: 0.4417\n",
      "Epoch [5/20], Batch [40/82], Loss: 0.4479\n",
      "Epoch [5/20], Batch [50/82], Loss: 0.5647\n",
      "Epoch [5/20], Batch [60/82], Loss: 0.5062\n",
      "Epoch [5/20], Batch [70/82], Loss: 0.4271\n",
      "Epoch [5/20], Batch [80/82], Loss: 0.3599\n",
      "Epoch [5/20] - 32.77s - Loss: 0.5213, Acc: 0.7239, Val Loss: 0.8348, Val Acc: 0.5321\n",
      "Epoch [6/20], Batch [10/82], Loss: 0.4645\n",
      "Epoch [6/20], Batch [20/82], Loss: 0.6735\n",
      "Epoch [6/20], Batch [30/82], Loss: 0.2429\n",
      "Epoch [6/20], Batch [40/82], Loss: 0.5011\n",
      "Epoch [6/20], Batch [50/82], Loss: 0.3140\n",
      "Epoch [6/20], Batch [60/82], Loss: 0.4907\n",
      "Epoch [6/20], Batch [70/82], Loss: 0.4457\n",
      "Epoch [6/20], Batch [80/82], Loss: 0.2211\n",
      "Epoch [6/20] - 28.97s - Loss: 0.4096, Acc: 0.8083, Val Loss: 0.9148, Val Acc: 0.5229\n",
      "Epoch [7/20], Batch [10/82], Loss: 0.1695\n",
      "Epoch [7/20], Batch [20/82], Loss: 0.2325\n",
      "Epoch [7/20], Batch [30/82], Loss: 0.1759\n",
      "Epoch [7/20], Batch [40/82], Loss: 0.1599\n",
      "Epoch [7/20], Batch [50/82], Loss: 0.4957\n",
      "Epoch [7/20], Batch [60/82], Loss: 0.4294\n",
      "Epoch [7/20], Batch [70/82], Loss: 0.2165\n",
      "Epoch [7/20], Batch [80/82], Loss: 0.1733\n",
      "Epoch [7/20] - 32.52s - Loss: 0.2939, Acc: 0.8597, Val Loss: 1.3039, Val Acc: 0.5260\n",
      "Early stopping triggered after epoch 7\n",
      "Loaded best model with validation loss: 0.6925\n",
      "Row-wise Model training history saved to 'row-wise_training_history.png'\n",
      "\n",
      "----- Training Column-wise Model -----\n",
      "Epoch [1/20], Batch [10/82], Loss: 0.9431\n",
      "Epoch [1/20], Batch [20/82], Loss: 0.6501\n",
      "Epoch [1/20], Batch [30/82], Loss: 0.7436\n",
      "Epoch [1/20], Batch [40/82], Loss: 0.7014\n",
      "Epoch [1/20], Batch [50/82], Loss: 0.8065\n",
      "Epoch [1/20], Batch [60/82], Loss: 0.7028\n",
      "Epoch [1/20], Batch [70/82], Loss: 0.7329\n",
      "Epoch [1/20], Batch [80/82], Loss: 0.7142\n",
      "Epoch [1/20] - 2.77s - Loss: 0.7294, Acc: 0.4732, Val Loss: 0.6923, Val Acc: 0.5015\n",
      "Epoch [2/20], Batch [10/82], Loss: 0.7101\n",
      "Epoch [2/20], Batch [20/82], Loss: 0.6753\n",
      "Epoch [2/20], Batch [30/82], Loss: 0.7672\n",
      "Epoch [2/20], Batch [40/82], Loss: 0.6697\n",
      "Epoch [2/20], Batch [50/82], Loss: 0.6647\n",
      "Epoch [2/20], Batch [60/82], Loss: 0.6659\n",
      "Epoch [2/20], Batch [70/82], Loss: 0.7338\n",
      "Epoch [2/20], Batch [80/82], Loss: 0.6567\n",
      "Epoch [2/20] - 2.53s - Loss: 0.6836, Acc: 0.5698, Val Loss: 0.7015, Val Acc: 0.4924\n",
      "Epoch [3/20], Batch [10/82], Loss: 0.6081\n",
      "Epoch [3/20], Batch [20/82], Loss: 0.5688\n",
      "Epoch [3/20], Batch [30/82], Loss: 0.5802\n",
      "Epoch [3/20], Batch [40/82], Loss: 0.6476\n",
      "Epoch [3/20], Batch [50/82], Loss: 0.5044\n",
      "Epoch [3/20], Batch [60/82], Loss: 0.7211\n",
      "Epoch [3/20], Batch [70/82], Loss: 0.6479\n",
      "Epoch [3/20], Batch [80/82], Loss: 0.7569\n",
      "Epoch [3/20] - 2.42s - Loss: 0.6365, Acc: 0.6434, Val Loss: 0.7401, Val Acc: 0.5321\n",
      "Epoch [4/20], Batch [10/82], Loss: 0.3513\n",
      "Epoch [4/20], Batch [20/82], Loss: 0.6677\n",
      "Epoch [4/20], Batch [30/82], Loss: 0.4938\n",
      "Epoch [4/20], Batch [40/82], Loss: 0.4958\n",
      "Epoch [4/20], Batch [50/82], Loss: 0.4747\n",
      "Epoch [4/20], Batch [60/82], Loss: 0.6085\n",
      "Epoch [4/20], Batch [70/82], Loss: 0.4376\n",
      "Epoch [4/20], Batch [80/82], Loss: 0.4986\n",
      "Epoch [4/20] - 2.51s - Loss: 0.5294, Acc: 0.7439, Val Loss: 0.7834, Val Acc: 0.5015\n",
      "Epoch [5/20], Batch [10/82], Loss: 0.4258\n",
      "Epoch [5/20], Batch [20/82], Loss: 0.2259\n",
      "Epoch [5/20], Batch [30/82], Loss: 0.4412\n",
      "Epoch [5/20], Batch [40/82], Loss: 0.3795\n",
      "Epoch [5/20], Batch [50/82], Loss: 0.4393\n",
      "Epoch [5/20], Batch [60/82], Loss: 0.2200\n",
      "Epoch [5/20], Batch [70/82], Loss: 0.3523\n",
      "Epoch [5/20], Batch [80/82], Loss: 0.4402\n",
      "Epoch [5/20] - 2.50s - Loss: 0.4080, Acc: 0.7845, Val Loss: 0.9355, Val Acc: 0.5291\n",
      "Epoch [6/20], Batch [10/82], Loss: 0.2560\n",
      "Epoch [6/20], Batch [20/82], Loss: 0.4960\n",
      "Epoch [6/20], Batch [30/82], Loss: 0.3073\n",
      "Epoch [6/20], Batch [40/82], Loss: 0.4543\n",
      "Epoch [6/20], Batch [50/82], Loss: 0.3443\n",
      "Epoch [6/20], Batch [60/82], Loss: 0.5314\n",
      "Epoch [6/20], Batch [70/82], Loss: 0.2768\n",
      "Epoch [6/20], Batch [80/82], Loss: 0.3653\n",
      "Epoch [6/20] - 2.70s - Loss: 0.3571, Acc: 0.8259, Val Loss: 1.2722, Val Acc: 0.5138\n",
      "Early stopping triggered after epoch 6\n",
      "Loaded best model with validation loss: 0.6923\n",
      "Column-wise Model training history saved to 'column-wise_training_history.png'\n",
      "\n",
      "Model Performance Comparison:\n",
      "Row-wise Model Best Validation Loss: 0.6925\n",
      "Column-wise Model Best Validation Loss: 0.6923\n"
     ]
    }
   ],
   "source": [
    "# Train both models\n",
    "row_model_trained, row_best_loss = train_model(\"Row-wise\", row_model, train_loader, test_loader, device, criterion, learning_rate=0.001, num_epochs=20)\n",
    "col_model_trained, col_best_loss = train_model(\"Column-wise\", col_model, train_loader, test_loader, device, criterion, learning_rate=0.001, num_epochs=20)\n",
    "\n",
    "# Compare model performances\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(f\"Row-wise Model Best Validation Loss: {row_best_loss:.4f}\")\n",
    "print(f\"Column-wise Model Best Validation Loss: {col_best_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-wise Model performed better and will be used for evaluation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if row_best_loss < col_best_loss:\n",
    "    better_model = row_model_trained\n",
    "    better_model_name = \"Row-wise\"\n",
    "    print(\"Row-wise Model performed better and will be used for evaluation\")\n",
    "else:\n",
    "    better_model = col_model_trained\n",
    "    better_model_name = \"Column-wise\"\n",
    "    print(\"Column-wise Model performed better and will be used for evaluation\")\n",
    "\n",
    "# Set the best model for further evaluation\n",
    "model = better_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to 'training_history.png'\n"
     ]
    }
   ],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(val_accs, label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()\n",
    "print(\"Training history saved to 'training_history.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9: Evaluating both models\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Evaluate both models\n",
    "print(\"\\nStep 9: Evaluating both models\")\n",
    "\n",
    "def evaluate_model(model_name, model, test_loader, device):\n",
    "    print(f\"\\n----- Evaluating {model_name} Model -----\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize arrays to store predictions and true labels\n",
    "    all_preds = []\n",
    "    all_preds_prob = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Test the model\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Convert to CPU and numpy for evaluation\n",
    "            preds_prob = outputs.cpu().numpy()\n",
    "            preds = (outputs > 0.5).float().cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            \n",
    "            # Append batch predictions to lists\n",
    "            all_preds.extend(preds)\n",
    "            all_preds_prob.extend(preds_prob)\n",
    "            all_labels.extend(labels)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_preds_prob = np.array(all_preds_prob).flatten()\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    print(f\"\\n{model_name} Model Classification Report:\")\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    print(report)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    print(f\"\\n{model_name} Model Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} Model - Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f'{model_name.lower()}_roc_curve.png')\n",
    "    plt.close()\n",
    "    print(f\"ROC curve saved to '{model_name.lower()}_roc_curve.png'\")\n",
    "    \n",
    "    return all_preds, all_preds_prob, all_labels, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Evaluating Row-wise Model -----\n",
      "\n",
      "Row-wise Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.47      0.50       164\n",
      "         1.0       0.52      0.58      0.55       163\n",
      "\n",
      "    accuracy                           0.53       327\n",
      "   macro avg       0.53      0.53      0.52       327\n",
      "weighted avg       0.53      0.53      0.52       327\n",
      "\n",
      "\n",
      "Row-wise Model Confusion Matrix:\n",
      "[[77 87]\n",
      " [68 95]]\n",
      "ROC curve saved to 'row-wise_roc_curve.png'\n",
      "\n",
      "----- Evaluating Column-wise Model -----\n",
      "\n",
      "Column-wise Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.52      0.52       164\n",
      "         1.0       0.51      0.51      0.51       163\n",
      "\n",
      "    accuracy                           0.51       327\n",
      "   macro avg       0.51      0.51      0.51       327\n",
      "weighted avg       0.51      0.51      0.51       327\n",
      "\n",
      "\n",
      "Column-wise Model Confusion Matrix:\n",
      "[[85 79]\n",
      " [80 83]]\n",
      "ROC curve saved to 'column-wise_roc_curve.png'\n",
      "\n",
      "Model ROC AUC Comparison:\n",
      "Row-wise Model AUC: 0.5517\n",
      "Column-wise Model AUC: 0.5232\n",
      "Row-wise Model has better AUC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate both models\n",
    "row_preds, row_preds_prob, row_labels, row_auc = evaluate_model(\"Row-wise\", row_model_trained, test_loader, device)\n",
    "col_preds, col_preds_prob, col_labels, col_auc = evaluate_model(\"Column-wise\", col_model_trained, test_loader, device)\n",
    "\n",
    "# Compare model ROC AUCs\n",
    "print(\"\\nModel ROC AUC Comparison:\")\n",
    "print(f\"Row-wise Model AUC: {row_auc:.4f}\")\n",
    "print(f\"Column-wise Model AUC: {col_auc:.4f}\")\n",
    "\n",
    "if row_auc > col_auc:\n",
    "    print(\"Row-wise Model has better AUC\")\n",
    "    final_model_name = \"Row-wise\"\n",
    "    final_preds = row_preds\n",
    "    final_preds_prob = row_preds_prob\n",
    "    final_labels = row_labels\n",
    "else:\n",
    "    print(\"Column-wise Model has better AUC\")\n",
    "    final_model_name = \"Column-wise\"\n",
    "    final_preds = col_preds\n",
    "    final_preds_prob = col_preds_prob\n",
    "    final_labels = col_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e8924a95e0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a combined ROC curve plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Row-wise model ROC\n",
    "fpr_row, tpr_row, _ = roc_curve(row_labels, row_preds_prob)\n",
    "plt.plot(fpr_row, tpr_row, color='blue', lw=2, label=f'Row-wise (AUC = {row_auc:.3f})')\n",
    "\n",
    "# Column-wise model ROC\n",
    "fpr_col, tpr_col, _ = roc_curve(col_labels, col_preds_prob)\n",
    "plt.plot(fpr_col, tpr_col, color='red', lw=2, label=f'Column-wise (AUC = {col_auc:.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined ROC curve saved to 'combined_roc_curve.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjhha\\AppData\\Local\\Temp\\ipykernel_14512\\2405286142.py:9: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(loc=\"lower right\")\n"
     ]
    }
   ],
   "source": [
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model Comparison - Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('combined_roc_curve.png')\n",
    "plt.close()\n",
    "print(\"Combined ROC curve saved to 'combined_roc_curve.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 10: Saving results\n",
      "Row-wise model saved to 'chagas_row_model.pth'\n",
      "Column-wise model saved to 'chagas_col_model.pth'\n",
      "\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.46      0.50       164\n",
      "         1.0       0.53      0.61      0.57       163\n",
      "\n",
      "    accuracy                           0.54       327\n",
      "   macro avg       0.54      0.54      0.53       327\n",
      "weighted avg       0.54      0.54      0.53       327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 10: Save models and results\n",
    "print(\"\\nStep 10: Saving results\")\n",
    "\n",
    "# Save both PyTorch models\n",
    "torch.save(row_model_trained.state_dict(), 'chagas_row_model.pth')\n",
    "print(\"Row-wise model saved to 'chagas_row_model.pth'\")\n",
    "\n",
    "torch.save(col_model_trained.state_dict(), 'chagas_col_model.pth')\n",
    "print(\"Column-wise model saved to 'chagas_col_model.pth'\")\n",
    "\n",
    "# Map back to original exam IDs\n",
    "original_test_ids = [original_ids[i] for i in test_indices]\n",
    "\n",
    "# Create DataFrame with predictions from both models\n",
    "predictions_df = pd.DataFrame({\n",
    "    'exam_id': original_test_ids,\n",
    "    'true_chagas': final_labels,\n",
    "    'row_predicted_prob': row_preds_prob,\n",
    "    'row_predicted_chagas': row_preds,\n",
    "    'col_predicted_prob': col_preds_prob,\n",
    "    'col_predicted_chagas': col_preds\n",
    "})\n",
    "\n",
    "# Add ensemble prediction (average of both models)\n",
    "predictions_df['ensemble_prob'] = (predictions_df['row_predicted_prob'] + predictions_df['col_predicted_prob']) / 2\n",
    "predictions_df['ensemble_chagas'] = (predictions_df['ensemble_prob'] > 0.5).astype(int)\n",
    "\n",
    "# Calculate ensemble metrics\n",
    "print(\"\\nEnsemble Model Classification Report:\")\n",
    "print(classification_report(predictions_df['true_chagas'], predictions_df['ensemble_chagas']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model AUC: 0.5456\n",
      "Ensemble ROC curve saved to 'ensemble_roc_curve.png'\n"
     ]
    }
   ],
   "source": [
    "# Calculate ensemble ROC AUC\n",
    "fpr_ensemble, tpr_ensemble, _ = roc_curve(predictions_df['true_chagas'], predictions_df['ensemble_prob'])\n",
    "ensemble_auc = auc(fpr_ensemble, tpr_ensemble)\n",
    "print(f\"Ensemble Model AUC: {ensemble_auc:.4f}\")\n",
    "\n",
    "# Add ensemble to the ROC curve comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Row-wise model ROC\n",
    "plt.plot(fpr_row, tpr_row, color='blue', lw=2, label=f'Row-wise (AUC = {row_auc:.3f})')\n",
    "# Column-wise model ROC\n",
    "plt.plot(fpr_col, tpr_col, color='red', lw=2, label=f'Column-wise (AUC = {col_auc:.3f})')\n",
    "# Ensemble model ROC\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, color='green', lw=2, label=f'Ensemble (AUC = {ensemble_auc:.3f})')\n",
    "# Diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Model Comparison - Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('ensemble_roc_curve.png')\n",
    "plt.close()\n",
    "print(\"Ensemble ROC curve saved to 'ensemble_roc_curve.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'chagas_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('chagas_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'chagas_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 11: Model Characteristics Comparison\n",
      "\n",
      "Model Comparison Summary:\n",
      "      Model      AUC  Accuracy  Sensitivity  Specificity                      Prediction Approach\n",
      "   Row-wise 0.551736  0.525994     0.582822     0.469512             Analyzes each lead over time\n",
      "Column-wise 0.523156  0.513761     0.509202     0.518293 Analyzes across leads at each time point\n",
      "   Ensemble 0.545563  0.535168     0.613497     0.457317    Average of Row and Column predictions\n",
      "Model comparison saved to 'model_comparison.csv'\n",
      "\n",
      "Script completed successfully!\n",
      "\n",
      "----------------------------------------------\n",
      "Key findings:\n",
      "1. Row-wise model (lead-based analysis) achieved AUC of 0.5517\n",
      "2. Column-wise model (time-point analysis) achieved AUC of 0.5232\n",
      "3. Ensemble model (combined approach) achieved AUC of 0.5456\n",
      "4. Best performing single approach: Row-wise\n",
      "5. All models were saved and can be used for future predictions\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Compare model characteristics\n",
    "print(\"\\nStep 11: Model Characteristics Comparison\")\n",
    "\n",
    "# Create a comparison summary\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Row-wise', 'Column-wise', 'Ensemble'],\n",
    "    'AUC': [row_auc, col_auc, ensemble_auc],\n",
    "    'Accuracy': [\n",
    "        (row_preds == final_labels).mean(), \n",
    "        (col_preds == final_labels).mean(), \n",
    "        (predictions_df['ensemble_chagas'] == predictions_df['true_chagas']).mean()\n",
    "    ],\n",
    "    'Sensitivity': [\n",
    "        recall_score(final_labels, row_preds, pos_label=1),\n",
    "        recall_score(final_labels, col_preds, pos_label=1),\n",
    "        recall_score(predictions_df['true_chagas'], predictions_df['ensemble_chagas'], pos_label=1)\n",
    "    ],\n",
    "    'Specificity': [\n",
    "        recall_score(final_labels, row_preds, pos_label=0),\n",
    "        recall_score(final_labels, col_preds, pos_label=0),\n",
    "        recall_score(predictions_df['true_chagas'], predictions_df['ensemble_chagas'], pos_label=0)\n",
    "    ],\n",
    "    'Prediction Approach': [\n",
    "        'Analyzes each lead over time', \n",
    "        'Analyzes across leads at each time point', \n",
    "        'Average of Row and Column predictions'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison to CSV\n",
    "comparison_df.to_csv('model_comparison.csv', index=False)\n",
    "print(\"Model comparison saved to 'model_comparison.csv'\")\n",
    "\n",
    "print(\"\\nScript completed successfully!\")\n",
    "print(\"\\n----------------------------------------------\")\n",
    "print(\"Key findings:\")\n",
    "print(f\"1. Row-wise model (lead-based analysis) achieved AUC of {row_auc:.4f}\")\n",
    "print(f\"2. Column-wise model (time-point analysis) achieved AUC of {col_auc:.4f}\")\n",
    "print(f\"3. Ensemble model (combined approach) achieved AUC of {ensemble_auc:.4f}\")\n",
    "print(f\"4. Best performing single approach: {'Row-wise' if row_auc > col_auc else 'Column-wise'}\")\n",
    "print(\"5. All models were saved and can be used for future predictions\")\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
